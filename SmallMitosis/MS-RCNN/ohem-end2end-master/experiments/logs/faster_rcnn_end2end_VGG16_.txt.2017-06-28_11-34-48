+ echo Logging output to experiments/logs/faster_rcnn_end2end_VGG16_.txt.2017-06-28_11-34-48
Logging output to experiments/logs/faster_rcnn_end2end_VGG16_.txt.2017-06-28_11-34-48
+ ./tools/train_net.py --gpu 0 --solver models/pascal_voc/VGG16/FP_Net_end2end/solver.prototxt --weights data/imagenet_models/VGG16.v2.caffemodel --imdb voc_2007_trainval --iters 70000 --cfg experiments/cfgs/FP_Net_end2end.yml
Called with args:
Namespace(cfg_file='experiments/cfgs/FP_Net_end2end.yml', gpu_id=0, imdb_name='voc_2007_trainval', max_iters=70000, pretrained_model='data/imagenet_models/VGG16.v2.caffemodel', randomize=False, set_cfgs=None, solver='models/pascal_voc/VGG16/FP_Net_end2end/solver.prototxt')
Using config:
{'DATA_DIR': '/home/ubuntu/Work/brbchen/unskychen/trying/p4/data',
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXP_DIR': 'FP_Net_end2end',
 'GPU_ID': 0,
 'MATLAB': 'matlab',
 'MODELS_DIR': '/home/ubuntu/Work/brbchen/unskychen/trying/p4/models/pascal_voc',
 'PIXEL_MEANS': array([[[ 102.9801,  115.9465,  122.7717]]]),
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Work/brbchen/unskychen/trying/p4',
 'TEST': {'BBOX_REG': True,
          'HAS_RPN': True,
          'MAX_SIZE': 1000,
          'NMS': 0.3,
          'PROPOSAL_METHOD': 'selective_search',
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.3,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALES': [600],
          'SVM': False},
 'TRAIN': {'ASPECT_GROUPING': True,
           'BATCH_SIZE': 256,
           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': True,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.3,
           'BG_THRESH_LO': 0.0,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.7,
           'HAS_RPN': True,
           'IMS_PER_BATCH': 1,
           'MAX_SIZE': 1000,
           'PROPOSAL_METHOD': 'gt',
           'RPN_BATCHSIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000,
           'SCALES': [600],
           'SNAPSHOT_INFIX': '',
           'SNAPSHOT_ITERS': 10000,
           'USE_FLIPPED': True,
           'USE_PREFETCH': False},
 'USE_GPU_NMS': True}
Loaded dataset `voc_2007_trainval` for training
Set proposal method: gt
Appending horizontally-flipped training examples...
voc_2007_trainval gt roidb loaded from /home/ubuntu/Work/brbchen/unskychen/trying/p4/data/cache/voc_2007_trainval_gt_roidb.pkl
done
Preparing training data...
done
33102 roidb entries
Output will be saved to `/home/ubuntu/Work/brbchen/unskychen/trying/p4/output/FP_Net_end2end/voc_2007_trainval`
Filtered 0 roidb entries: 33102 -> 33102
Computing bounding-box regression targets...
bbox target means:
[[ 0.  0.  0.  0.]
 [ 0.  0.  0.  0.]
 [ 0.  0.  0.  0.]
 [ 0.  0.  0.  0.]
 [ 0.  0.  0.  0.]
 [ 0.  0.  0.  0.]
 [ 0.  0.  0.  0.]
 [ 0.  0.  0.  0.]
 [ 0.  0.  0.  0.]
 [ 0.  0.  0.  0.]
 [ 0.  0.  0.  0.]
 [ 0.  0.  0.  0.]
 [ 0.  0.  0.  0.]
 [ 0.  0.  0.  0.]
 [ 0.  0.  0.  0.]
 [ 0.  0.  0.  0.]
 [ 0.  0.  0.  0.]
 [ 0.  0.  0.  0.]
 [ 0.  0.  0.  0.]
 [ 0.  0.  0.  0.]
 [ 0.  0.  0.  0.]]
[ 0.  0.  0.  0.]
bbox target stdevs:
[[ 0.1  0.1  0.2  0.2]
 [ 0.1  0.1  0.2  0.2]
 [ 0.1  0.1  0.2  0.2]
 [ 0.1  0.1  0.2  0.2]
 [ 0.1  0.1  0.2  0.2]
 [ 0.1  0.1  0.2  0.2]
 [ 0.1  0.1  0.2  0.2]
 [ 0.1  0.1  0.2  0.2]
 [ 0.1  0.1  0.2  0.2]
 [ 0.1  0.1  0.2  0.2]
 [ 0.1  0.1  0.2  0.2]
 [ 0.1  0.1  0.2  0.2]
 [ 0.1  0.1  0.2  0.2]
 [ 0.1  0.1  0.2  0.2]
 [ 0.1  0.1  0.2  0.2]
 [ 0.1  0.1  0.2  0.2]
 [ 0.1  0.1  0.2  0.2]
 [ 0.1  0.1  0.2  0.2]
 [ 0.1  0.1  0.2  0.2]
 [ 0.1  0.1  0.2  0.2]
 [ 0.1  0.1  0.2  0.2]]
[ 0.1  0.1  0.2  0.2]
Normalizing targets
done
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0628 11:35:06.647296 48903 solver.cpp:48] Initializing solver from parameters: 
train_net: "models/pascal_voc/VGG16/FP_Net_end2end/train.prototxt"
base_lr: 1e-05
display: 20
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 50000
snapshot: 0
snapshot_prefix: "fpn"
average_loss: 100
iter_size: 2
I0628 11:35:06.647354 48903 solver.cpp:81] Creating training net from train_net file: models/pascal_voc/VGG16/FP_Net_end2end/train.prototxt
I0628 11:35:06.648921 48903 net.cpp:49] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layers"
state {
  phase: TRAIN
}
layer {
  name: "input-data"
  type: "Python"
  top: "data"
  top: "im_info"
  top: "gt_boxes"
  python_param {
    module: "roi_data_layer.layer"
    layer: "RoIDataLayer"
    param_str: "\'num_classes\': 21"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "P5"
  type: "Convolution"
  bottom: "pool5"
  top: "P5"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "upP5"
  type: "Deconvolution"
  bottom: "P5"
  top: "upP5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 4
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "newC4"
  type: "Convolution"
  bottom: "conv5_3"
  top: "newC4"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "upP5crop"
  type: "Crop"
  bottom: "upP5"
  bottom: "newC4"
  top: "upP5crop"
  crop_param {
    axis: 2
    offset: 0
  }
}
layer {
  name: "P4"
  type: "Eltwise"
  bottom: "newC4"
  bottom: "upP5crop"
  top: "P4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "upP4"
  type: "Deconvolution"
  bottom: "P4"
  top: "upP4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 4
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "newC3"
  type: "Convolution"
  bottom: "conv4_3"
  top: "newC3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "upP4crop"
  type: "Crop"
  bottom: "upP4"
  bottom: "newC3"
  top: "upP4crop"
  crop_param {
    axis: 2
    offset: 0
  }
}
layer {
  name: "P3"
  type: "Eltwise"
  bottom: "newC3"
  bottom: "upP4crop"
  top: "P3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "upP3"
  type: "Deconvolution"
  bottom: "P3"
  top: "upP3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 4
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "upP3crop"
  type: "Crop"
  bottom: "upP3"
  bottom: "conv3_3"
  top: "upP3crop"
  crop_param {
    axis: 2
    offset: 0
  }
}
layer {
  name: "P2"
  type: "Eltwise"
  bottom: "conv3_3"
  bottom: "upP3crop"
  top: "P2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "newP2"
  type: "Convolution"
  bottom: "P2"
  top: "newP2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "rpn_conv/3x3"
  type: "Convolution"
  bottom: "newP2"
  top: "rpn/output"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_relu/3x3"
  type: "ReLU"
  bottom: "rpn/output"
  top: "rpn/output"
}
layer {
  name: "rpn_cls_score"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_cls_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 18
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_bbox_pred"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_bbox_pred"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 36
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_cls_score_reshape"
  type: "Reshape"
  bottom: "rpn_cls_score"
  top: "rpn_cls_score_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 2
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "rpn-data"
  type: "Python"
  bottom: "rpn_cls_score"
  bottom: "gt_boxes"
  bottom: "im_info"
  bottom: "data"
  top: "rpn_labels"
  top: "rpn_bbox_targets"
  top: "rpn_bbox_inside_weights"
  top: "rpn_bbox_outside_weights"
  python_param {
    module: "rpn.anchor_target_layer"
    layer: "AnchorTargetLayer"
    param_str: "\'feat_stride\': 4"
  }
}
layer {
  name: "rpn_loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "rpn_cls_score_reshape"
  bottom: "rpn_labels"
  top: "rpn_cls_loss"
  loss_weight: 1
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: -1
    normalize: true
  }
}
layer {
  name: "rpn_loss_bbox"
  type: "SmoothL1Loss"
  bottom: "rpn_bbox_pred"
  bottom: "rpn_bbox_targets"
  bottom: "rpn_bbox_inside_weights"
  bottom: "rpn_bbox_outside_weights"
  top: "rpn_loss_bbox"
  loss_weight: 1
  smooth_l1_loss_param {
    sigma: 3
  }
}
layer {
  name: "rpn_cls_prob"
  type: "Softmax"
  bottom: "rpn_cls_score_reshape"
  top: "rpn_cls_prob"
}
layer {
  name: "rpn_cls_prob_reshape"
  type: "Reshape"
  bottom: "rpn_cls_prob"
  top: "rpn_cls_prob_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 18
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "proposal"
  type: "Python"
  bottom: "rpn_cls_prob_reshape"
  bottom: "rpn_bbox_pred"
  bottom: "im_info"
  top: "rpn_rois"
  python_param {
    module: "rpn.proposal_layer"
    layer: "ProposalLayer"
    param_str: "\'feat_stride\': 4"
  }
}
layer {
  name: "roi-data"
  type: "Python"
  bottom: "rpn_rois"
  bottom: "gt_boxes"
  top: "rois"
  top: "labels"
  top: "bbox_targets"
  top: "bbox_inside_weights"
  top: "bbox_outside_weights"
  python_param {
    module: "rpn.proposal_target_layer"
    layer: "ProposalTargetLayer"
    param_str: "\'num_classes\': 21"
  }
}
layer {
  name: "roi_pool5"
  type: "ROIPooling"
  bottom: "newP2"
  bottom: "rois"
  top: "rcnn_pool5"
  roi_pooling_param {
    pooled_h: 7
    pooled_w: 7
    spatial_scale: 0.25
  }
}
layer {
  name: "rcnn_fc6"
  type: "InnerProduct"
  bottom: "rcnn_pool5"
  top: "rcnn_fc6"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "rcnn_fc6"
  top: "rcnn_fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "rcnn_fc6"
  top: "rcnn_fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "rcnn_fc6"
  top: "fc7"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "cls_score"
  type: "InnerProduct"
  bottom: "fc7"
  top: "cls_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 21
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bbox_pred"
  type: "InnerProduct"
  bottom: "fc7"
  top: "bbox_pred"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 84
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "cls_score"
  bottom: "labels"
  top: "loss_cls"
  loss_weight: 1
  propagate_down: true
  propagate_down: false
}
layer {
  name: "loss_bbox"
  type: "SmoothL1Loss"
  bottom: "bbox_pred"
  bottom: "bbox_targets"
  bottom: "bbox_inside_weights"
  bottom: "bbox_outside_weights"
  top: "loss_bbox"
  loss_weight: 1
}
I0628 11:35:06.649289 48903 layer_factory.hpp:77] Creating layer input-data
I0628 11:35:06.650183 48903 net.cpp:106] Creating Layer input-data
I0628 11:35:06.650208 48903 net.cpp:411] input-data -> data
I0628 11:35:06.650225 48903 net.cpp:411] input-data -> im_info
I0628 11:35:06.650259 48903 net.cpp:411] input-data -> gt_boxes
RoiDataLayer: name_to_top: {'gt_boxes': 2, 'data': 0, 'im_info': 1}
I0628 11:35:06.721006 48903 net.cpp:150] Setting up input-data
I0628 11:35:06.721037 48903 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0628 11:35:06.721062 48903 net.cpp:157] Top shape: 1 3 (3)
I0628 11:35:06.721073 48903 net.cpp:157] Top shape: 1 4 (4)
I0628 11:35:06.721076 48903 net.cpp:165] Memory required for data: 7200028
I0628 11:35:06.721081 48903 layer_factory.hpp:77] Creating layer data_input-data_0_split
I0628 11:35:06.721091 48903 net.cpp:106] Creating Layer data_input-data_0_split
I0628 11:35:06.721107 48903 net.cpp:454] data_input-data_0_split <- data
I0628 11:35:06.721115 48903 net.cpp:411] data_input-data_0_split -> data_input-data_0_split_0
I0628 11:35:06.721138 48903 net.cpp:411] data_input-data_0_split -> data_input-data_0_split_1
I0628 11:35:06.721184 48903 net.cpp:150] Setting up data_input-data_0_split
I0628 11:35:06.721196 48903 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0628 11:35:06.721201 48903 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0628 11:35:06.721204 48903 net.cpp:165] Memory required for data: 21600028
I0628 11:35:06.721207 48903 layer_factory.hpp:77] Creating layer im_info_input-data_1_split
I0628 11:35:06.721230 48903 net.cpp:106] Creating Layer im_info_input-data_1_split
I0628 11:35:06.721240 48903 net.cpp:454] im_info_input-data_1_split <- im_info
I0628 11:35:06.721247 48903 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_0
I0628 11:35:06.721258 48903 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_1
I0628 11:35:06.721297 48903 net.cpp:150] Setting up im_info_input-data_1_split
I0628 11:35:06.721307 48903 net.cpp:157] Top shape: 1 3 (3)
I0628 11:35:06.721310 48903 net.cpp:157] Top shape: 1 3 (3)
I0628 11:35:06.721313 48903 net.cpp:165] Memory required for data: 21600052
I0628 11:35:06.721318 48903 layer_factory.hpp:77] Creating layer gt_boxes_input-data_2_split
I0628 11:35:06.721338 48903 net.cpp:106] Creating Layer gt_boxes_input-data_2_split
I0628 11:35:06.721349 48903 net.cpp:454] gt_boxes_input-data_2_split <- gt_boxes
I0628 11:35:06.721355 48903 net.cpp:411] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_0
I0628 11:35:06.721361 48903 net.cpp:411] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_1
I0628 11:35:06.721395 48903 net.cpp:150] Setting up gt_boxes_input-data_2_split
I0628 11:35:06.721410 48903 net.cpp:157] Top shape: 1 4 (4)
I0628 11:35:06.721413 48903 net.cpp:157] Top shape: 1 4 (4)
I0628 11:35:06.721431 48903 net.cpp:165] Memory required for data: 21600084
I0628 11:35:06.721442 48903 layer_factory.hpp:77] Creating layer conv1_1
I0628 11:35:06.721454 48903 net.cpp:106] Creating Layer conv1_1
I0628 11:35:06.721459 48903 net.cpp:454] conv1_1 <- data_input-data_0_split_0
I0628 11:35:06.721467 48903 net.cpp:411] conv1_1 -> conv1_1
I0628 11:35:07.069821 48903 net.cpp:150] Setting up conv1_1
I0628 11:35:07.069875 48903 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0628 11:35:07.069878 48903 net.cpp:165] Memory required for data: 175200084
I0628 11:35:07.069898 48903 layer_factory.hpp:77] Creating layer relu1_1
I0628 11:35:07.069911 48903 net.cpp:106] Creating Layer relu1_1
I0628 11:35:07.069917 48903 net.cpp:454] relu1_1 <- conv1_1
I0628 11:35:07.069924 48903 net.cpp:397] relu1_1 -> conv1_1 (in-place)
I0628 11:35:07.070684 48903 net.cpp:150] Setting up relu1_1
I0628 11:35:07.070706 48903 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0628 11:35:07.070710 48903 net.cpp:165] Memory required for data: 328800084
I0628 11:35:07.070713 48903 layer_factory.hpp:77] Creating layer conv1_2
I0628 11:35:07.070724 48903 net.cpp:106] Creating Layer conv1_2
I0628 11:35:07.070751 48903 net.cpp:454] conv1_2 <- conv1_1
I0628 11:35:07.070766 48903 net.cpp:411] conv1_2 -> conv1_2
I0628 11:35:07.075423 48903 net.cpp:150] Setting up conv1_2
I0628 11:35:07.075449 48903 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0628 11:35:07.075453 48903 net.cpp:165] Memory required for data: 482400084
I0628 11:35:07.075465 48903 layer_factory.hpp:77] Creating layer relu1_2
I0628 11:35:07.075500 48903 net.cpp:106] Creating Layer relu1_2
I0628 11:35:07.075512 48903 net.cpp:454] relu1_2 <- conv1_2
I0628 11:35:07.075520 48903 net.cpp:397] relu1_2 -> conv1_2 (in-place)
I0628 11:35:07.075700 48903 net.cpp:150] Setting up relu1_2
I0628 11:35:07.075714 48903 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0628 11:35:07.075718 48903 net.cpp:165] Memory required for data: 636000084
I0628 11:35:07.075721 48903 layer_factory.hpp:77] Creating layer pool1
I0628 11:35:07.075757 48903 net.cpp:106] Creating Layer pool1
I0628 11:35:07.075769 48903 net.cpp:454] pool1 <- conv1_2
I0628 11:35:07.075776 48903 net.cpp:411] pool1 -> pool1
I0628 11:35:07.075848 48903 net.cpp:150] Setting up pool1
I0628 11:35:07.075863 48903 net.cpp:157] Top shape: 1 64 300 500 (9600000)
I0628 11:35:07.075866 48903 net.cpp:165] Memory required for data: 674400084
I0628 11:35:07.075870 48903 layer_factory.hpp:77] Creating layer conv2_1
I0628 11:35:07.075896 48903 net.cpp:106] Creating Layer conv2_1
I0628 11:35:07.075906 48903 net.cpp:454] conv2_1 <- pool1
I0628 11:35:07.075913 48903 net.cpp:411] conv2_1 -> conv2_1
I0628 11:35:07.078833 48903 net.cpp:150] Setting up conv2_1
I0628 11:35:07.078856 48903 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0628 11:35:07.078860 48903 net.cpp:165] Memory required for data: 751200084
I0628 11:35:07.078872 48903 layer_factory.hpp:77] Creating layer relu2_1
I0628 11:35:07.078902 48903 net.cpp:106] Creating Layer relu2_1
I0628 11:35:07.078914 48903 net.cpp:454] relu2_1 <- conv2_1
I0628 11:35:07.078923 48903 net.cpp:397] relu2_1 -> conv2_1 (in-place)
I0628 11:35:07.079131 48903 net.cpp:150] Setting up relu2_1
I0628 11:35:07.079149 48903 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0628 11:35:07.079154 48903 net.cpp:165] Memory required for data: 828000084
I0628 11:35:07.079156 48903 layer_factory.hpp:77] Creating layer conv2_2
I0628 11:35:07.079167 48903 net.cpp:106] Creating Layer conv2_2
I0628 11:35:07.079190 48903 net.cpp:454] conv2_2 <- conv2_1
I0628 11:35:07.079203 48903 net.cpp:411] conv2_2 -> conv2_2
I0628 11:35:07.082700 48903 net.cpp:150] Setting up conv2_2
I0628 11:35:07.082725 48903 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0628 11:35:07.082728 48903 net.cpp:165] Memory required for data: 904800084
I0628 11:35:07.082736 48903 layer_factory.hpp:77] Creating layer relu2_2
I0628 11:35:07.082742 48903 net.cpp:106] Creating Layer relu2_2
I0628 11:35:07.082746 48903 net.cpp:454] relu2_2 <- conv2_2
I0628 11:35:07.082753 48903 net.cpp:397] relu2_2 -> conv2_2 (in-place)
I0628 11:35:07.083597 48903 net.cpp:150] Setting up relu2_2
I0628 11:35:07.083618 48903 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0628 11:35:07.083622 48903 net.cpp:165] Memory required for data: 981600084
I0628 11:35:07.083626 48903 layer_factory.hpp:77] Creating layer pool2
I0628 11:35:07.083662 48903 net.cpp:106] Creating Layer pool2
I0628 11:35:07.083673 48903 net.cpp:454] pool2 <- conv2_2
I0628 11:35:07.083681 48903 net.cpp:411] pool2 -> pool2
I0628 11:35:07.083753 48903 net.cpp:150] Setting up pool2
I0628 11:35:07.083768 48903 net.cpp:157] Top shape: 1 128 150 250 (4800000)
I0628 11:35:07.083771 48903 net.cpp:165] Memory required for data: 1000800084
I0628 11:35:07.083775 48903 layer_factory.hpp:77] Creating layer conv3_1
I0628 11:35:07.083802 48903 net.cpp:106] Creating Layer conv3_1
I0628 11:35:07.083813 48903 net.cpp:454] conv3_1 <- pool2
I0628 11:35:07.083823 48903 net.cpp:411] conv3_1 -> conv3_1
I0628 11:35:07.086961 48903 net.cpp:150] Setting up conv3_1
I0628 11:35:07.086983 48903 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0628 11:35:07.086987 48903 net.cpp:165] Memory required for data: 1039200084
I0628 11:35:07.086999 48903 layer_factory.hpp:77] Creating layer relu3_1
I0628 11:35:07.087008 48903 net.cpp:106] Creating Layer relu3_1
I0628 11:35:07.087013 48903 net.cpp:454] relu3_1 <- conv3_1
I0628 11:35:07.087040 48903 net.cpp:397] relu3_1 -> conv3_1 (in-place)
I0628 11:35:07.087255 48903 net.cpp:150] Setting up relu3_1
I0628 11:35:07.087270 48903 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0628 11:35:07.087273 48903 net.cpp:165] Memory required for data: 1077600084
I0628 11:35:07.087277 48903 layer_factory.hpp:77] Creating layer conv3_2
I0628 11:35:07.087309 48903 net.cpp:106] Creating Layer conv3_2
I0628 11:35:07.087321 48903 net.cpp:454] conv3_2 <- conv3_1
I0628 11:35:07.087329 48903 net.cpp:411] conv3_2 -> conv3_2
I0628 11:35:07.091218 48903 net.cpp:150] Setting up conv3_2
I0628 11:35:07.091248 48903 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0628 11:35:07.091253 48903 net.cpp:165] Memory required for data: 1116000084
I0628 11:35:07.091260 48903 layer_factory.hpp:77] Creating layer relu3_2
I0628 11:35:07.091294 48903 net.cpp:106] Creating Layer relu3_2
I0628 11:35:07.091305 48903 net.cpp:454] relu3_2 <- conv3_2
I0628 11:35:07.091315 48903 net.cpp:397] relu3_2 -> conv3_2 (in-place)
I0628 11:35:07.091564 48903 net.cpp:150] Setting up relu3_2
I0628 11:35:07.091583 48903 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0628 11:35:07.091586 48903 net.cpp:165] Memory required for data: 1154400084
I0628 11:35:07.091589 48903 layer_factory.hpp:77] Creating layer conv3_3
I0628 11:35:07.091620 48903 net.cpp:106] Creating Layer conv3_3
I0628 11:35:07.091632 48903 net.cpp:454] conv3_3 <- conv3_2
I0628 11:35:07.091641 48903 net.cpp:411] conv3_3 -> conv3_3
I0628 11:35:07.095551 48903 net.cpp:150] Setting up conv3_3
I0628 11:35:07.095578 48903 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0628 11:35:07.095582 48903 net.cpp:165] Memory required for data: 1192800084
I0628 11:35:07.095590 48903 layer_factory.hpp:77] Creating layer relu3_3
I0628 11:35:07.095621 48903 net.cpp:106] Creating Layer relu3_3
I0628 11:35:07.095633 48903 net.cpp:454] relu3_3 <- conv3_3
I0628 11:35:07.095649 48903 net.cpp:397] relu3_3 -> conv3_3 (in-place)
I0628 11:35:07.096408 48903 net.cpp:150] Setting up relu3_3
I0628 11:35:07.096432 48903 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0628 11:35:07.096457 48903 net.cpp:165] Memory required for data: 1231200084
I0628 11:35:07.096467 48903 layer_factory.hpp:77] Creating layer conv3_3_relu3_3_0_split
I0628 11:35:07.096477 48903 net.cpp:106] Creating Layer conv3_3_relu3_3_0_split
I0628 11:35:07.096479 48903 net.cpp:454] conv3_3_relu3_3_0_split <- conv3_3
I0628 11:35:07.096487 48903 net.cpp:411] conv3_3_relu3_3_0_split -> conv3_3_relu3_3_0_split_0
I0628 11:35:07.096494 48903 net.cpp:411] conv3_3_relu3_3_0_split -> conv3_3_relu3_3_0_split_1
I0628 11:35:07.096499 48903 net.cpp:411] conv3_3_relu3_3_0_split -> conv3_3_relu3_3_0_split_2
I0628 11:35:07.096566 48903 net.cpp:150] Setting up conv3_3_relu3_3_0_split
I0628 11:35:07.096580 48903 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0628 11:35:07.096583 48903 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0628 11:35:07.096587 48903 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0628 11:35:07.096590 48903 net.cpp:165] Memory required for data: 1346400084
I0628 11:35:07.096611 48903 layer_factory.hpp:77] Creating layer pool3
I0628 11:35:07.096627 48903 net.cpp:106] Creating Layer pool3
I0628 11:35:07.096647 48903 net.cpp:454] pool3 <- conv3_3_relu3_3_0_split_0
I0628 11:35:07.096659 48903 net.cpp:411] pool3 -> pool3
I0628 11:35:07.096712 48903 net.cpp:150] Setting up pool3
I0628 11:35:07.096724 48903 net.cpp:157] Top shape: 1 256 75 125 (2400000)
I0628 11:35:07.096727 48903 net.cpp:165] Memory required for data: 1356000084
I0628 11:35:07.096731 48903 layer_factory.hpp:77] Creating layer conv4_1
I0628 11:35:07.096757 48903 net.cpp:106] Creating Layer conv4_1
I0628 11:35:07.096768 48903 net.cpp:454] conv4_1 <- pool3
I0628 11:35:07.096776 48903 net.cpp:411] conv4_1 -> conv4_1
I0628 11:35:07.103148 48903 net.cpp:150] Setting up conv4_1
I0628 11:35:07.103184 48903 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0628 11:35:07.103189 48903 net.cpp:165] Memory required for data: 1375200084
I0628 11:35:07.103197 48903 layer_factory.hpp:77] Creating layer relu4_1
I0628 11:35:07.103237 48903 net.cpp:106] Creating Layer relu4_1
I0628 11:35:07.103250 48903 net.cpp:454] relu4_1 <- conv4_1
I0628 11:35:07.103257 48903 net.cpp:397] relu4_1 -> conv4_1 (in-place)
I0628 11:35:07.104046 48903 net.cpp:150] Setting up relu4_1
I0628 11:35:07.104069 48903 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0628 11:35:07.104095 48903 net.cpp:165] Memory required for data: 1394400084
I0628 11:35:07.104106 48903 layer_factory.hpp:77] Creating layer conv4_2
I0628 11:35:07.104116 48903 net.cpp:106] Creating Layer conv4_2
I0628 11:35:07.104135 48903 net.cpp:454] conv4_2 <- conv4_1
I0628 11:35:07.104151 48903 net.cpp:411] conv4_2 -> conv4_2
I0628 11:35:07.112467 48903 net.cpp:150] Setting up conv4_2
I0628 11:35:07.112511 48903 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0628 11:35:07.112516 48903 net.cpp:165] Memory required for data: 1413600084
I0628 11:35:07.112532 48903 layer_factory.hpp:77] Creating layer relu4_2
I0628 11:35:07.112581 48903 net.cpp:106] Creating Layer relu4_2
I0628 11:35:07.112596 48903 net.cpp:454] relu4_2 <- conv4_2
I0628 11:35:07.112603 48903 net.cpp:397] relu4_2 -> conv4_2 (in-place)
I0628 11:35:07.112823 48903 net.cpp:150] Setting up relu4_2
I0628 11:35:07.112840 48903 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0628 11:35:07.112844 48903 net.cpp:165] Memory required for data: 1432800084
I0628 11:35:07.112848 48903 layer_factory.hpp:77] Creating layer conv4_3
I0628 11:35:07.112860 48903 net.cpp:106] Creating Layer conv4_3
I0628 11:35:07.112866 48903 net.cpp:454] conv4_3 <- conv4_2
I0628 11:35:07.112874 48903 net.cpp:411] conv4_3 -> conv4_3
I0628 11:35:07.120645 48903 net.cpp:150] Setting up conv4_3
I0628 11:35:07.120683 48903 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0628 11:35:07.120688 48903 net.cpp:165] Memory required for data: 1452000084
I0628 11:35:07.120697 48903 layer_factory.hpp:77] Creating layer relu4_3
I0628 11:35:07.120707 48903 net.cpp:106] Creating Layer relu4_3
I0628 11:35:07.120743 48903 net.cpp:454] relu4_3 <- conv4_3
I0628 11:35:07.120760 48903 net.cpp:397] relu4_3 -> conv4_3 (in-place)
I0628 11:35:07.121513 48903 net.cpp:150] Setting up relu4_3
I0628 11:35:07.121533 48903 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0628 11:35:07.121536 48903 net.cpp:165] Memory required for data: 1471200084
I0628 11:35:07.121541 48903 layer_factory.hpp:77] Creating layer conv4_3_relu4_3_0_split
I0628 11:35:07.121547 48903 net.cpp:106] Creating Layer conv4_3_relu4_3_0_split
I0628 11:35:07.121551 48903 net.cpp:454] conv4_3_relu4_3_0_split <- conv4_3
I0628 11:35:07.121558 48903 net.cpp:411] conv4_3_relu4_3_0_split -> conv4_3_relu4_3_0_split_0
I0628 11:35:07.121565 48903 net.cpp:411] conv4_3_relu4_3_0_split -> conv4_3_relu4_3_0_split_1
I0628 11:35:07.121644 48903 net.cpp:150] Setting up conv4_3_relu4_3_0_split
I0628 11:35:07.121661 48903 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0628 11:35:07.121665 48903 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0628 11:35:07.121685 48903 net.cpp:165] Memory required for data: 1509600084
I0628 11:35:07.121695 48903 layer_factory.hpp:77] Creating layer pool4
I0628 11:35:07.121702 48903 net.cpp:106] Creating Layer pool4
I0628 11:35:07.121718 48903 net.cpp:454] pool4 <- conv4_3_relu4_3_0_split_0
I0628 11:35:07.121731 48903 net.cpp:411] pool4 -> pool4
I0628 11:35:07.121785 48903 net.cpp:150] Setting up pool4
I0628 11:35:07.121798 48903 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0628 11:35:07.121800 48903 net.cpp:165] Memory required for data: 1514502996
I0628 11:35:07.121803 48903 layer_factory.hpp:77] Creating layer conv5_1
I0628 11:35:07.121831 48903 net.cpp:106] Creating Layer conv5_1
I0628 11:35:07.121843 48903 net.cpp:454] conv5_1 <- pool4
I0628 11:35:07.121851 48903 net.cpp:411] conv5_1 -> conv5_1
I0628 11:35:07.129652 48903 net.cpp:150] Setting up conv5_1
I0628 11:35:07.129699 48903 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0628 11:35:07.129704 48903 net.cpp:165] Memory required for data: 1519405908
I0628 11:35:07.129712 48903 layer_factory.hpp:77] Creating layer relu5_1
I0628 11:35:07.129726 48903 net.cpp:106] Creating Layer relu5_1
I0628 11:35:07.129763 48903 net.cpp:454] relu5_1 <- conv5_1
I0628 11:35:07.129781 48903 net.cpp:397] relu5_1 -> conv5_1 (in-place)
I0628 11:35:07.129990 48903 net.cpp:150] Setting up relu5_1
I0628 11:35:07.130005 48903 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0628 11:35:07.130009 48903 net.cpp:165] Memory required for data: 1524308820
I0628 11:35:07.130012 48903 layer_factory.hpp:77] Creating layer conv5_2
I0628 11:35:07.130051 48903 net.cpp:106] Creating Layer conv5_2
I0628 11:35:07.130062 48903 net.cpp:454] conv5_2 <- conv5_1
I0628 11:35:07.130071 48903 net.cpp:411] conv5_2 -> conv5_2
I0628 11:35:07.138191 48903 net.cpp:150] Setting up conv5_2
I0628 11:35:07.138238 48903 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0628 11:35:07.138243 48903 net.cpp:165] Memory required for data: 1529211732
I0628 11:35:07.138252 48903 layer_factory.hpp:77] Creating layer relu5_2
I0628 11:35:07.138260 48903 net.cpp:106] Creating Layer relu5_2
I0628 11:35:07.138298 48903 net.cpp:454] relu5_2 <- conv5_2
I0628 11:35:07.138317 48903 net.cpp:397] relu5_2 -> conv5_2 (in-place)
I0628 11:35:07.138535 48903 net.cpp:150] Setting up relu5_2
I0628 11:35:07.138551 48903 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0628 11:35:07.138555 48903 net.cpp:165] Memory required for data: 1534114644
I0628 11:35:07.138558 48903 layer_factory.hpp:77] Creating layer conv5_3
I0628 11:35:07.138569 48903 net.cpp:106] Creating Layer conv5_3
I0628 11:35:07.138574 48903 net.cpp:454] conv5_3 <- conv5_2
I0628 11:35:07.138583 48903 net.cpp:411] conv5_3 -> conv5_3
I0628 11:35:07.146628 48903 net.cpp:150] Setting up conv5_3
I0628 11:35:07.146677 48903 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0628 11:35:07.146682 48903 net.cpp:165] Memory required for data: 1539017556
I0628 11:35:07.146692 48903 layer_factory.hpp:77] Creating layer relu5_3
I0628 11:35:07.146703 48903 net.cpp:106] Creating Layer relu5_3
I0628 11:35:07.146744 48903 net.cpp:454] relu5_3 <- conv5_3
I0628 11:35:07.146761 48903 net.cpp:397] relu5_3 -> conv5_3 (in-place)
I0628 11:35:07.147577 48903 net.cpp:150] Setting up relu5_3
I0628 11:35:07.147598 48903 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0628 11:35:07.147603 48903 net.cpp:165] Memory required for data: 1543920468
I0628 11:35:07.147605 48903 layer_factory.hpp:77] Creating layer conv5_3_relu5_3_0_split
I0628 11:35:07.147613 48903 net.cpp:106] Creating Layer conv5_3_relu5_3_0_split
I0628 11:35:07.147616 48903 net.cpp:454] conv5_3_relu5_3_0_split <- conv5_3
I0628 11:35:07.147621 48903 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_0
I0628 11:35:07.147630 48903 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_1
I0628 11:35:07.147717 48903 net.cpp:150] Setting up conv5_3_relu5_3_0_split
I0628 11:35:07.147737 48903 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0628 11:35:07.147742 48903 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0628 11:35:07.147744 48903 net.cpp:165] Memory required for data: 1553726292
I0628 11:35:07.147749 48903 layer_factory.hpp:77] Creating layer pool5
I0628 11:35:07.147756 48903 net.cpp:106] Creating Layer pool5
I0628 11:35:07.147759 48903 net.cpp:454] pool5 <- conv5_3_relu5_3_0_split_0
I0628 11:35:07.147766 48903 net.cpp:411] pool5 -> pool5
I0628 11:35:07.147835 48903 net.cpp:150] Setting up pool5
I0628 11:35:07.147852 48903 net.cpp:157] Top shape: 1 512 19 32 (311296)
I0628 11:35:07.147856 48903 net.cpp:165] Memory required for data: 1554971476
I0628 11:35:07.147860 48903 layer_factory.hpp:77] Creating layer P5
I0628 11:35:07.147869 48903 net.cpp:106] Creating Layer P5
I0628 11:35:07.147891 48903 net.cpp:454] P5 <- pool5
I0628 11:35:07.147908 48903 net.cpp:411] P5 -> P5
I0628 11:35:07.151124 48903 net.cpp:150] Setting up P5
I0628 11:35:07.151149 48903 net.cpp:157] Top shape: 1 256 19 32 (155648)
I0628 11:35:07.151152 48903 net.cpp:165] Memory required for data: 1555594068
I0628 11:35:07.151183 48903 layer_factory.hpp:77] Creating layer upP5
I0628 11:35:07.151208 48903 net.cpp:106] Creating Layer upP5
I0628 11:35:07.151223 48903 net.cpp:454] upP5 <- P5
I0628 11:35:07.151229 48903 net.cpp:411] upP5 -> upP5
I0628 11:35:07.177793 48903 net.cpp:150] Setting up upP5
I0628 11:35:07.177847 48903 net.cpp:157] Top shape: 1 256 38 64 (622592)
I0628 11:35:07.177852 48903 net.cpp:165] Memory required for data: 1558084436
I0628 11:35:07.177861 48903 layer_factory.hpp:77] Creating layer newC4
I0628 11:35:07.177881 48903 net.cpp:106] Creating Layer newC4
I0628 11:35:07.177887 48903 net.cpp:454] newC4 <- conv5_3_relu5_3_0_split_1
I0628 11:35:07.177897 48903 net.cpp:411] newC4 -> newC4
I0628 11:35:07.180867 48903 net.cpp:150] Setting up newC4
I0628 11:35:07.180892 48903 net.cpp:157] Top shape: 1 256 38 63 (612864)
I0628 11:35:07.180896 48903 net.cpp:165] Memory required for data: 1560535892
I0628 11:35:07.180903 48903 layer_factory.hpp:77] Creating layer newC4_newC4_0_split
I0628 11:35:07.180933 48903 net.cpp:106] Creating Layer newC4_newC4_0_split
I0628 11:35:07.180945 48903 net.cpp:454] newC4_newC4_0_split <- newC4
I0628 11:35:07.180955 48903 net.cpp:411] newC4_newC4_0_split -> newC4_newC4_0_split_0
I0628 11:35:07.180977 48903 net.cpp:411] newC4_newC4_0_split -> newC4_newC4_0_split_1
I0628 11:35:07.181041 48903 net.cpp:150] Setting up newC4_newC4_0_split
I0628 11:35:07.181056 48903 net.cpp:157] Top shape: 1 256 38 63 (612864)
I0628 11:35:07.181059 48903 net.cpp:157] Top shape: 1 256 38 63 (612864)
I0628 11:35:07.181079 48903 net.cpp:165] Memory required for data: 1565438804
I0628 11:35:07.181090 48903 layer_factory.hpp:77] Creating layer upP5crop
I0628 11:35:07.181102 48903 net.cpp:106] Creating Layer upP5crop
I0628 11:35:07.181115 48903 net.cpp:454] upP5crop <- upP5
I0628 11:35:07.181120 48903 net.cpp:454] upP5crop <- newC4_newC4_0_split_0
I0628 11:35:07.181125 48903 net.cpp:411] upP5crop -> upP5crop
I0628 11:35:07.181264 48903 net.cpp:150] Setting up upP5crop
I0628 11:35:07.181278 48903 net.cpp:157] Top shape: 1 256 38 63 (612864)
I0628 11:35:07.181282 48903 net.cpp:165] Memory required for data: 1567890260
I0628 11:35:07.181285 48903 layer_factory.hpp:77] Creating layer P4
I0628 11:35:07.181313 48903 net.cpp:106] Creating Layer P4
I0628 11:35:07.181324 48903 net.cpp:454] P4 <- newC4_newC4_0_split_1
I0628 11:35:07.181329 48903 net.cpp:454] P4 <- upP5crop
I0628 11:35:07.181334 48903 net.cpp:411] P4 -> P4
I0628 11:35:07.181375 48903 net.cpp:150] Setting up P4
I0628 11:35:07.181386 48903 net.cpp:157] Top shape: 1 256 38 63 (612864)
I0628 11:35:07.181390 48903 net.cpp:165] Memory required for data: 1570341716
I0628 11:35:07.181393 48903 layer_factory.hpp:77] Creating layer upP4
I0628 11:35:07.181421 48903 net.cpp:106] Creating Layer upP4
I0628 11:35:07.181432 48903 net.cpp:454] upP4 <- P4
I0628 11:35:07.181438 48903 net.cpp:411] upP4 -> upP4
I0628 11:35:07.207435 48903 net.cpp:150] Setting up upP4
I0628 11:35:07.207459 48903 net.cpp:157] Top shape: 1 256 76 126 (2451456)
I0628 11:35:07.207463 48903 net.cpp:165] Memory required for data: 1580147540
I0628 11:35:07.207468 48903 layer_factory.hpp:77] Creating layer newC3
I0628 11:35:07.207480 48903 net.cpp:106] Creating Layer newC3
I0628 11:35:07.207510 48903 net.cpp:454] newC3 <- conv4_3_relu4_3_0_split_1
I0628 11:35:07.207525 48903 net.cpp:411] newC3 -> newC3
I0628 11:35:07.211464 48903 net.cpp:150] Setting up newC3
I0628 11:35:07.211489 48903 net.cpp:157] Top shape: 1 256 75 125 (2400000)
I0628 11:35:07.211516 48903 net.cpp:165] Memory required for data: 1589747540
I0628 11:35:07.211539 48903 layer_factory.hpp:77] Creating layer newC3_newC3_0_split
I0628 11:35:07.211565 48903 net.cpp:106] Creating Layer newC3_newC3_0_split
I0628 11:35:07.211575 48903 net.cpp:454] newC3_newC3_0_split <- newC3
I0628 11:35:07.211582 48903 net.cpp:411] newC3_newC3_0_split -> newC3_newC3_0_split_0
I0628 11:35:07.211604 48903 net.cpp:411] newC3_newC3_0_split -> newC3_newC3_0_split_1
I0628 11:35:07.211669 48903 net.cpp:150] Setting up newC3_newC3_0_split
I0628 11:35:07.211683 48903 net.cpp:157] Top shape: 1 256 75 125 (2400000)
I0628 11:35:07.211688 48903 net.cpp:157] Top shape: 1 256 75 125 (2400000)
I0628 11:35:07.211689 48903 net.cpp:165] Memory required for data: 1608947540
I0628 11:35:07.211694 48903 layer_factory.hpp:77] Creating layer upP4crop
I0628 11:35:07.211719 48903 net.cpp:106] Creating Layer upP4crop
I0628 11:35:07.211729 48903 net.cpp:454] upP4crop <- upP4
I0628 11:35:07.211735 48903 net.cpp:454] upP4crop <- newC3_newC3_0_split_0
I0628 11:35:07.211738 48903 net.cpp:411] upP4crop -> upP4crop
I0628 11:35:07.211856 48903 net.cpp:150] Setting up upP4crop
I0628 11:35:07.211868 48903 net.cpp:157] Top shape: 1 256 75 125 (2400000)
I0628 11:35:07.211870 48903 net.cpp:165] Memory required for data: 1618547540
I0628 11:35:07.211874 48903 layer_factory.hpp:77] Creating layer P3
I0628 11:35:07.211879 48903 net.cpp:106] Creating Layer P3
I0628 11:35:07.211882 48903 net.cpp:454] P3 <- newC3_newC3_0_split_1
I0628 11:35:07.211886 48903 net.cpp:454] P3 <- upP4crop
I0628 11:35:07.211890 48903 net.cpp:411] P3 -> P3
I0628 11:35:07.211916 48903 net.cpp:150] Setting up P3
I0628 11:35:07.211926 48903 net.cpp:157] Top shape: 1 256 75 125 (2400000)
I0628 11:35:07.211930 48903 net.cpp:165] Memory required for data: 1628147540
I0628 11:35:07.211932 48903 layer_factory.hpp:77] Creating layer upP3
I0628 11:35:07.211941 48903 net.cpp:106] Creating Layer upP3
I0628 11:35:07.211944 48903 net.cpp:454] upP3 <- P3
I0628 11:35:07.211951 48903 net.cpp:411] upP3 -> upP3
I0628 11:35:07.238672 48903 net.cpp:150] Setting up upP3
I0628 11:35:07.238696 48903 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0628 11:35:07.238700 48903 net.cpp:165] Memory required for data: 1666547540
I0628 11:35:07.238708 48903 layer_factory.hpp:77] Creating layer upP3crop
I0628 11:35:07.238718 48903 net.cpp:106] Creating Layer upP3crop
I0628 11:35:07.238721 48903 net.cpp:454] upP3crop <- upP3
I0628 11:35:07.238726 48903 net.cpp:454] upP3crop <- conv3_3_relu3_3_0_split_1
I0628 11:35:07.238731 48903 net.cpp:411] upP3crop -> upP3crop
I0628 11:35:07.238868 48903 net.cpp:150] Setting up upP3crop
I0628 11:35:07.238883 48903 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0628 11:35:07.238885 48903 net.cpp:165] Memory required for data: 1704947540
I0628 11:35:07.238888 48903 layer_factory.hpp:77] Creating layer P2
I0628 11:35:07.238893 48903 net.cpp:106] Creating Layer P2
I0628 11:35:07.238896 48903 net.cpp:454] P2 <- conv3_3_relu3_3_0_split_2
I0628 11:35:07.238900 48903 net.cpp:454] P2 <- upP3crop
I0628 11:35:07.238907 48903 net.cpp:411] P2 -> P2
I0628 11:35:07.238934 48903 net.cpp:150] Setting up P2
I0628 11:35:07.238945 48903 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0628 11:35:07.238948 48903 net.cpp:165] Memory required for data: 1743347540
I0628 11:35:07.238951 48903 layer_factory.hpp:77] Creating layer newP2
I0628 11:35:07.238961 48903 net.cpp:106] Creating Layer newP2
I0628 11:35:07.238965 48903 net.cpp:454] newP2 <- P2
I0628 11:35:07.238971 48903 net.cpp:411] newP2 -> newP2
I0628 11:35:07.245147 48903 net.cpp:150] Setting up newP2
I0628 11:35:07.245172 48903 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0628 11:35:07.245177 48903 net.cpp:165] Memory required for data: 1781747540
I0628 11:35:07.245183 48903 layer_factory.hpp:77] Creating layer newP2_newP2_0_split
I0628 11:35:07.245190 48903 net.cpp:106] Creating Layer newP2_newP2_0_split
I0628 11:35:07.245193 48903 net.cpp:454] newP2_newP2_0_split <- newP2
I0628 11:35:07.245199 48903 net.cpp:411] newP2_newP2_0_split -> newP2_newP2_0_split_0
I0628 11:35:07.245208 48903 net.cpp:411] newP2_newP2_0_split -> newP2_newP2_0_split_1
I0628 11:35:07.245265 48903 net.cpp:150] Setting up newP2_newP2_0_split
I0628 11:35:07.245277 48903 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0628 11:35:07.245281 48903 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0628 11:35:07.245285 48903 net.cpp:165] Memory required for data: 1858547540
I0628 11:35:07.245287 48903 layer_factory.hpp:77] Creating layer rpn_conv/3x3
I0628 11:35:07.245299 48903 net.cpp:106] Creating Layer rpn_conv/3x3
I0628 11:35:07.245303 48903 net.cpp:454] rpn_conv/3x3 <- newP2_newP2_0_split_0
I0628 11:35:07.245308 48903 net.cpp:411] rpn_conv/3x3 -> rpn/output
I0628 11:35:07.277760 48903 net.cpp:150] Setting up rpn_conv/3x3
I0628 11:35:07.277786 48903 net.cpp:157] Top shape: 1 512 150 250 (19200000)
I0628 11:35:07.277789 48903 net.cpp:165] Memory required for data: 1935347540
I0628 11:35:07.277799 48903 layer_factory.hpp:77] Creating layer rpn_relu/3x3
I0628 11:35:07.277809 48903 net.cpp:106] Creating Layer rpn_relu/3x3
I0628 11:35:07.277813 48903 net.cpp:454] rpn_relu/3x3 <- rpn/output
I0628 11:35:07.277822 48903 net.cpp:397] rpn_relu/3x3 -> rpn/output (in-place)
I0628 11:35:07.278023 48903 net.cpp:150] Setting up rpn_relu/3x3
I0628 11:35:07.278040 48903 net.cpp:157] Top shape: 1 512 150 250 (19200000)
I0628 11:35:07.278043 48903 net.cpp:165] Memory required for data: 2012147540
I0628 11:35:07.278046 48903 layer_factory.hpp:77] Creating layer rpn/output_rpn_relu/3x3_0_split
I0628 11:35:07.278053 48903 net.cpp:106] Creating Layer rpn/output_rpn_relu/3x3_0_split
I0628 11:35:07.278055 48903 net.cpp:454] rpn/output_rpn_relu/3x3_0_split <- rpn/output
I0628 11:35:07.278062 48903 net.cpp:411] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_0
I0628 11:35:07.278069 48903 net.cpp:411] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_1
I0628 11:35:07.278118 48903 net.cpp:150] Setting up rpn/output_rpn_relu/3x3_0_split
I0628 11:35:07.278133 48903 net.cpp:157] Top shape: 1 512 150 250 (19200000)
I0628 11:35:07.278137 48903 net.cpp:157] Top shape: 1 512 150 250 (19200000)
I0628 11:35:07.278141 48903 net.cpp:165] Memory required for data: 2165747540
I0628 11:35:07.278143 48903 layer_factory.hpp:77] Creating layer rpn_cls_score
I0628 11:35:07.278153 48903 net.cpp:106] Creating Layer rpn_cls_score
I0628 11:35:07.278157 48903 net.cpp:454] rpn_cls_score <- rpn/output_rpn_relu/3x3_0_split_0
I0628 11:35:07.278163 48903 net.cpp:411] rpn_cls_score -> rpn_cls_score
I0628 11:35:07.281767 48903 net.cpp:150] Setting up rpn_cls_score
I0628 11:35:07.281793 48903 net.cpp:157] Top shape: 1 18 150 250 (675000)
I0628 11:35:07.281797 48903 net.cpp:165] Memory required for data: 2168447540
I0628 11:35:07.281805 48903 layer_factory.hpp:77] Creating layer rpn_cls_score_rpn_cls_score_0_split
I0628 11:35:07.281810 48903 net.cpp:106] Creating Layer rpn_cls_score_rpn_cls_score_0_split
I0628 11:35:07.281821 48903 net.cpp:454] rpn_cls_score_rpn_cls_score_0_split <- rpn_cls_score
I0628 11:35:07.281827 48903 net.cpp:411] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_0
I0628 11:35:07.281833 48903 net.cpp:411] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_1
I0628 11:35:07.281888 48903 net.cpp:150] Setting up rpn_cls_score_rpn_cls_score_0_split
I0628 11:35:07.281901 48903 net.cpp:157] Top shape: 1 18 150 250 (675000)
I0628 11:35:07.281905 48903 net.cpp:157] Top shape: 1 18 150 250 (675000)
I0628 11:35:07.281908 48903 net.cpp:165] Memory required for data: 2173847540
I0628 11:35:07.281911 48903 layer_factory.hpp:77] Creating layer rpn_bbox_pred
I0628 11:35:07.281921 48903 net.cpp:106] Creating Layer rpn_bbox_pred
I0628 11:35:07.281927 48903 net.cpp:454] rpn_bbox_pred <- rpn/output_rpn_relu/3x3_0_split_1
I0628 11:35:07.281932 48903 net.cpp:411] rpn_bbox_pred -> rpn_bbox_pred
I0628 11:35:07.285914 48903 net.cpp:150] Setting up rpn_bbox_pred
I0628 11:35:07.285938 48903 net.cpp:157] Top shape: 1 36 150 250 (1350000)
I0628 11:35:07.285943 48903 net.cpp:165] Memory required for data: 2179247540
I0628 11:35:07.285949 48903 layer_factory.hpp:77] Creating layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0628 11:35:07.285959 48903 net.cpp:106] Creating Layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0628 11:35:07.285977 48903 net.cpp:454] rpn_bbox_pred_rpn_bbox_pred_0_split <- rpn_bbox_pred
I0628 11:35:07.285984 48903 net.cpp:411] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0628 11:35:07.285989 48903 net.cpp:411] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0628 11:35:07.286043 48903 net.cpp:150] Setting up rpn_bbox_pred_rpn_bbox_pred_0_split
I0628 11:35:07.286056 48903 net.cpp:157] Top shape: 1 36 150 250 (1350000)
I0628 11:35:07.286061 48903 net.cpp:157] Top shape: 1 36 150 250 (1350000)
I0628 11:35:07.286062 48903 net.cpp:165] Memory required for data: 2190047540
I0628 11:35:07.286065 48903 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape
I0628 11:35:07.286074 48903 net.cpp:106] Creating Layer rpn_cls_score_reshape
I0628 11:35:07.286078 48903 net.cpp:454] rpn_cls_score_reshape <- rpn_cls_score_rpn_cls_score_0_split_0
I0628 11:35:07.286085 48903 net.cpp:411] rpn_cls_score_reshape -> rpn_cls_score_reshape
I0628 11:35:07.286118 48903 net.cpp:150] Setting up rpn_cls_score_reshape
I0628 11:35:07.286129 48903 net.cpp:157] Top shape: 1 2 1350 250 (675000)
I0628 11:35:07.286133 48903 net.cpp:165] Memory required for data: 2192747540
I0628 11:35:07.286135 48903 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0628 11:35:07.286144 48903 net.cpp:106] Creating Layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0628 11:35:07.286147 48903 net.cpp:454] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split <- rpn_cls_score_reshape
I0628 11:35:07.286151 48903 net.cpp:411] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0628 11:35:07.286159 48903 net.cpp:411] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0628 11:35:07.286208 48903 net.cpp:150] Setting up rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0628 11:35:07.286219 48903 net.cpp:157] Top shape: 1 2 1350 250 (675000)
I0628 11:35:07.286224 48903 net.cpp:157] Top shape: 1 2 1350 250 (675000)
I0628 11:35:07.286226 48903 net.cpp:165] Memory required for data: 2198147540
I0628 11:35:07.286229 48903 layer_factory.hpp:77] Creating layer rpn-data
I0628 11:35:07.286958 48903 net.cpp:106] Creating Layer rpn-data
I0628 11:35:07.286979 48903 net.cpp:454] rpn-data <- rpn_cls_score_rpn_cls_score_0_split_1
I0628 11:35:07.286986 48903 net.cpp:454] rpn-data <- gt_boxes_input-data_2_split_0
I0628 11:35:07.286991 48903 net.cpp:454] rpn-data <- im_info_input-data_1_split_0
I0628 11:35:07.286995 48903 net.cpp:454] rpn-data <- data_input-data_0_split_1
I0628 11:35:07.287000 48903 net.cpp:411] rpn-data -> rpn_labels
I0628 11:35:07.287008 48903 net.cpp:411] rpn-data -> rpn_bbox_targets
I0628 11:35:07.287014 48903 net.cpp:411] rpn-data -> rpn_bbox_inside_weights
I0628 11:35:07.287019 48903 net.cpp:411] rpn-data -> rpn_bbox_outside_weights
I0628 11:35:07.289530 48903 net.cpp:150] Setting up rpn-data
I0628 11:35:07.289556 48903 net.cpp:157] Top shape: 1 1 1350 250 (337500)
I0628 11:35:07.289562 48903 net.cpp:157] Top shape: 1 36 150 250 (1350000)
I0628 11:35:07.289566 48903 net.cpp:157] Top shape: 1 36 150 250 (1350000)
I0628 11:35:07.289569 48903 net.cpp:157] Top shape: 1 36 150 250 (1350000)
I0628 11:35:07.289572 48903 net.cpp:165] Memory required for data: 2215697540
I0628 11:35:07.289575 48903 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0628 11:35:07.289597 48903 net.cpp:106] Creating Layer rpn_loss_cls
I0628 11:35:07.289608 48903 net.cpp:454] rpn_loss_cls <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0628 11:35:07.289613 48903 net.cpp:454] rpn_loss_cls <- rpn_labels
I0628 11:35:07.289618 48903 net.cpp:411] rpn_loss_cls -> rpn_cls_loss
I0628 11:35:07.289633 48903 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0628 11:35:07.291709 48903 net.cpp:150] Setting up rpn_loss_cls
I0628 11:35:07.291734 48903 net.cpp:157] Top shape: (1)
I0628 11:35:07.291738 48903 net.cpp:160]     with loss weight 1
I0628 11:35:07.291764 48903 net.cpp:165] Memory required for data: 2215697544
I0628 11:35:07.291769 48903 layer_factory.hpp:77] Creating layer rpn_loss_bbox
I0628 11:35:07.291779 48903 net.cpp:106] Creating Layer rpn_loss_bbox
I0628 11:35:07.291784 48903 net.cpp:454] rpn_loss_bbox <- rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0628 11:35:07.291788 48903 net.cpp:454] rpn_loss_bbox <- rpn_bbox_targets
I0628 11:35:07.291792 48903 net.cpp:454] rpn_loss_bbox <- rpn_bbox_inside_weights
I0628 11:35:07.291796 48903 net.cpp:454] rpn_loss_bbox <- rpn_bbox_outside_weights
I0628 11:35:07.291801 48903 net.cpp:411] rpn_loss_bbox -> rpn_loss_bbox
I0628 11:35:07.301355 48903 net.cpp:150] Setting up rpn_loss_bbox
I0628 11:35:07.301379 48903 net.cpp:157] Top shape: (1)
I0628 11:35:07.301383 48903 net.cpp:160]     with loss weight 1
I0628 11:35:07.301390 48903 net.cpp:165] Memory required for data: 2215697548
I0628 11:35:07.301393 48903 layer_factory.hpp:77] Creating layer rpn_cls_prob
I0628 11:35:07.301400 48903 net.cpp:106] Creating Layer rpn_cls_prob
I0628 11:35:07.301404 48903 net.cpp:454] rpn_cls_prob <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0628 11:35:07.301409 48903 net.cpp:411] rpn_cls_prob -> rpn_cls_prob
I0628 11:35:07.302275 48903 net.cpp:150] Setting up rpn_cls_prob
I0628 11:35:07.302296 48903 net.cpp:157] Top shape: 1 2 1350 250 (675000)
I0628 11:35:07.302300 48903 net.cpp:165] Memory required for data: 2218397548
I0628 11:35:07.302304 48903 layer_factory.hpp:77] Creating layer rpn_cls_prob_reshape
I0628 11:35:07.302310 48903 net.cpp:106] Creating Layer rpn_cls_prob_reshape
I0628 11:35:07.302314 48903 net.cpp:454] rpn_cls_prob_reshape <- rpn_cls_prob
I0628 11:35:07.302321 48903 net.cpp:411] rpn_cls_prob_reshape -> rpn_cls_prob_reshape
I0628 11:35:07.302356 48903 net.cpp:150] Setting up rpn_cls_prob_reshape
I0628 11:35:07.302367 48903 net.cpp:157] Top shape: 1 18 150 250 (675000)
I0628 11:35:07.302371 48903 net.cpp:165] Memory required for data: 2221097548
I0628 11:35:07.302374 48903 layer_factory.hpp:77] Creating layer proposal
I0628 11:35:07.303257 48903 net.cpp:106] Creating Layer proposal
I0628 11:35:07.303280 48903 net.cpp:454] proposal <- rpn_cls_prob_reshape
I0628 11:35:07.303287 48903 net.cpp:454] proposal <- rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0628 11:35:07.303292 48903 net.cpp:454] proposal <- im_info_input-data_1_split_1
I0628 11:35:07.303297 48903 net.cpp:411] proposal -> rpn_rois
I0628 11:35:07.306085 48903 net.cpp:150] Setting up proposal
I0628 11:35:07.306109 48903 net.cpp:157] Top shape: 1 5 (5)
I0628 11:35:07.306113 48903 net.cpp:165] Memory required for data: 2221097568
I0628 11:35:07.306118 48903 layer_factory.hpp:77] Creating layer roi-data
I0628 11:35:07.306299 48903 net.cpp:106] Creating Layer roi-data
I0628 11:35:07.306318 48903 net.cpp:454] roi-data <- rpn_rois
I0628 11:35:07.306324 48903 net.cpp:454] roi-data <- gt_boxes_input-data_2_split_1
I0628 11:35:07.306330 48903 net.cpp:411] roi-data -> rois
I0628 11:35:07.306337 48903 net.cpp:411] roi-data -> labels
I0628 11:35:07.306344 48903 net.cpp:411] roi-data -> bbox_targets
I0628 11:35:07.306355 48903 net.cpp:411] roi-data -> bbox_inside_weights
I0628 11:35:07.306361 48903 net.cpp:411] roi-data -> bbox_outside_weights
I0628 11:35:07.306754 48903 net.cpp:150] Setting up roi-data
I0628 11:35:07.306797 48903 net.cpp:157] Top shape: 1 5 (5)
I0628 11:35:07.306802 48903 net.cpp:157] Top shape: 1 1 (1)
I0628 11:35:07.306805 48903 net.cpp:157] Top shape: 1 84 (84)
I0628 11:35:07.306808 48903 net.cpp:157] Top shape: 1 84 (84)
I0628 11:35:07.306812 48903 net.cpp:157] Top shape: 1 84 (84)
I0628 11:35:07.306814 48903 net.cpp:165] Memory required for data: 2221098600
I0628 11:35:07.306818 48903 layer_factory.hpp:77] Creating layer roi_pool5
I0628 11:35:07.306830 48903 net.cpp:106] Creating Layer roi_pool5
I0628 11:35:07.306838 48903 net.cpp:454] roi_pool5 <- newP2_newP2_0_split_1
I0628 11:35:07.306843 48903 net.cpp:454] roi_pool5 <- rois
I0628 11:35:07.306848 48903 net.cpp:411] roi_pool5 -> rcnn_pool5
I0628 11:35:07.306855 48903 roi_pooling_layer.cpp:30] Spatial scale: 0.25
I0628 11:35:07.306922 48903 net.cpp:150] Setting up roi_pool5
I0628 11:35:07.306934 48903 net.cpp:157] Top shape: 1 256 7 7 (12544)
I0628 11:35:07.306938 48903 net.cpp:165] Memory required for data: 2221148776
I0628 11:35:07.306941 48903 layer_factory.hpp:77] Creating layer rcnn_fc6
I0628 11:35:07.306949 48903 net.cpp:106] Creating Layer rcnn_fc6
I0628 11:35:07.306953 48903 net.cpp:454] rcnn_fc6 <- rcnn_pool5
I0628 11:35:07.306958 48903 net.cpp:411] rcnn_fc6 -> rcnn_fc6
I0628 11:35:07.646358 48903 net.cpp:150] Setting up rcnn_fc6
I0628 11:35:07.646415 48903 net.cpp:157] Top shape: 1 4096 (4096)
I0628 11:35:07.646420 48903 net.cpp:165] Memory required for data: 2221165160
I0628 11:35:07.646432 48903 layer_factory.hpp:77] Creating layer relu6
I0628 11:35:07.646445 48903 net.cpp:106] Creating Layer relu6
I0628 11:35:07.646451 48903 net.cpp:454] relu6 <- rcnn_fc6
I0628 11:35:07.646458 48903 net.cpp:397] relu6 -> rcnn_fc6 (in-place)
I0628 11:35:07.647548 48903 net.cpp:150] Setting up relu6
I0628 11:35:07.647569 48903 net.cpp:157] Top shape: 1 4096 (4096)
I0628 11:35:07.647573 48903 net.cpp:165] Memory required for data: 2221181544
I0628 11:35:07.647578 48903 layer_factory.hpp:77] Creating layer drop6
I0628 11:35:07.647591 48903 net.cpp:106] Creating Layer drop6
I0628 11:35:07.647629 48903 net.cpp:454] drop6 <- rcnn_fc6
I0628 11:35:07.647652 48903 net.cpp:397] drop6 -> rcnn_fc6 (in-place)
I0628 11:35:07.647716 48903 net.cpp:150] Setting up drop6
I0628 11:35:07.647743 48903 net.cpp:157] Top shape: 1 4096 (4096)
I0628 11:35:07.647758 48903 net.cpp:165] Memory required for data: 2221197928
I0628 11:35:07.647773 48903 layer_factory.hpp:77] Creating layer fc7
I0628 11:35:07.647791 48903 net.cpp:106] Creating Layer fc7
I0628 11:35:07.647806 48903 net.cpp:454] fc7 <- rcnn_fc6
I0628 11:35:07.647825 48903 net.cpp:411] fc7 -> fc7
I0628 11:35:07.760850 48903 net.cpp:150] Setting up fc7
I0628 11:35:07.760905 48903 net.cpp:157] Top shape: 1 4096 (4096)
I0628 11:35:07.760910 48903 net.cpp:165] Memory required for data: 2221214312
I0628 11:35:07.760921 48903 layer_factory.hpp:77] Creating layer relu7
I0628 11:35:07.760931 48903 net.cpp:106] Creating Layer relu7
I0628 11:35:07.760937 48903 net.cpp:454] relu7 <- fc7
I0628 11:35:07.760946 48903 net.cpp:397] relu7 -> fc7 (in-place)
I0628 11:35:07.761217 48903 net.cpp:150] Setting up relu7
I0628 11:35:07.761234 48903 net.cpp:157] Top shape: 1 4096 (4096)
I0628 11:35:07.761237 48903 net.cpp:165] Memory required for data: 2221230696
I0628 11:35:07.761241 48903 layer_factory.hpp:77] Creating layer drop7
I0628 11:35:07.761247 48903 net.cpp:106] Creating Layer drop7
I0628 11:35:07.761278 48903 net.cpp:454] drop7 <- fc7
I0628 11:35:07.761298 48903 net.cpp:397] drop7 -> fc7 (in-place)
I0628 11:35:07.761344 48903 net.cpp:150] Setting up drop7
I0628 11:35:07.761355 48903 net.cpp:157] Top shape: 1 4096 (4096)
I0628 11:35:07.761358 48903 net.cpp:165] Memory required for data: 2221247080
I0628 11:35:07.761363 48903 layer_factory.hpp:77] Creating layer fc7_drop7_0_split
I0628 11:35:07.761370 48903 net.cpp:106] Creating Layer fc7_drop7_0_split
I0628 11:35:07.761394 48903 net.cpp:454] fc7_drop7_0_split <- fc7
I0628 11:35:07.761405 48903 net.cpp:411] fc7_drop7_0_split -> fc7_drop7_0_split_0
I0628 11:35:07.761411 48903 net.cpp:411] fc7_drop7_0_split -> fc7_drop7_0_split_1
I0628 11:35:07.761492 48903 net.cpp:150] Setting up fc7_drop7_0_split
I0628 11:35:07.761507 48903 net.cpp:157] Top shape: 1 4096 (4096)
I0628 11:35:07.761510 48903 net.cpp:157] Top shape: 1 4096 (4096)
I0628 11:35:07.761513 48903 net.cpp:165] Memory required for data: 2221279848
I0628 11:35:07.761517 48903 layer_factory.hpp:77] Creating layer cls_score
I0628 11:35:07.761544 48903 net.cpp:106] Creating Layer cls_score
I0628 11:35:07.761554 48903 net.cpp:454] cls_score <- fc7_drop7_0_split_0
I0628 11:35:07.761562 48903 net.cpp:411] cls_score -> cls_score
I0628 11:35:07.763800 48903 net.cpp:150] Setting up cls_score
I0628 11:35:07.763819 48903 net.cpp:157] Top shape: 1 21 (21)
I0628 11:35:07.763823 48903 net.cpp:165] Memory required for data: 2221279932
I0628 11:35:07.763828 48903 layer_factory.hpp:77] Creating layer bbox_pred
I0628 11:35:07.763835 48903 net.cpp:106] Creating Layer bbox_pred
I0628 11:35:07.763860 48903 net.cpp:454] bbox_pred <- fc7_drop7_0_split_1
I0628 11:35:07.763878 48903 net.cpp:411] bbox_pred -> bbox_pred
I0628 11:35:07.773131 48903 net.cpp:150] Setting up bbox_pred
I0628 11:35:07.773182 48903 net.cpp:157] Top shape: 1 84 (84)
I0628 11:35:07.773186 48903 net.cpp:165] Memory required for data: 2221280268
I0628 11:35:07.773196 48903 layer_factory.hpp:77] Creating layer loss_cls
I0628 11:35:07.773208 48903 net.cpp:106] Creating Layer loss_cls
I0628 11:35:07.773223 48903 net.cpp:454] loss_cls <- cls_score
I0628 11:35:07.773231 48903 net.cpp:454] loss_cls <- labels
I0628 11:35:07.773237 48903 net.cpp:411] loss_cls -> loss_cls
I0628 11:35:07.773247 48903 layer_factory.hpp:77] Creating layer loss_cls
I0628 11:35:07.774370 48903 net.cpp:150] Setting up loss_cls
I0628 11:35:07.774394 48903 net.cpp:157] Top shape: (1)
I0628 11:35:07.774397 48903 net.cpp:160]     with loss weight 1
I0628 11:35:07.774448 48903 net.cpp:165] Memory required for data: 2221280272
I0628 11:35:07.774484 48903 layer_factory.hpp:77] Creating layer loss_bbox
I0628 11:35:07.774507 48903 net.cpp:106] Creating Layer loss_bbox
I0628 11:35:07.774529 48903 net.cpp:454] loss_bbox <- bbox_pred
I0628 11:35:07.774546 48903 net.cpp:454] loss_bbox <- bbox_targets
I0628 11:35:07.774564 48903 net.cpp:454] loss_bbox <- bbox_inside_weights
I0628 11:35:07.774580 48903 net.cpp:454] loss_bbox <- bbox_outside_weights
I0628 11:35:07.774596 48903 net.cpp:411] loss_bbox -> loss_bbox
I0628 11:35:07.774742 48903 net.cpp:150] Setting up loss_bbox
I0628 11:35:07.774760 48903 net.cpp:157] Top shape: (1)
I0628 11:35:07.774763 48903 net.cpp:160]     with loss weight 1
I0628 11:35:07.774791 48903 net.cpp:165] Memory required for data: 2221280276
I0628 11:35:07.774796 48903 net.cpp:226] loss_bbox needs backward computation.
I0628 11:35:07.774798 48903 net.cpp:226] loss_cls needs backward computation.
I0628 11:35:07.774802 48903 net.cpp:226] bbox_pred needs backward computation.
I0628 11:35:07.774806 48903 net.cpp:226] cls_score needs backward computation.
I0628 11:35:07.774808 48903 net.cpp:226] fc7_drop7_0_split needs backward computation.
I0628 11:35:07.774811 48903 net.cpp:226] drop7 needs backward computation.
I0628 11:35:07.774816 48903 net.cpp:226] relu7 needs backward computation.
I0628 11:35:07.774817 48903 net.cpp:226] fc7 needs backward computation.
I0628 11:35:07.774821 48903 net.cpp:226] drop6 needs backward computation.
I0628 11:35:07.774824 48903 net.cpp:226] relu6 needs backward computation.
I0628 11:35:07.774827 48903 net.cpp:226] rcnn_fc6 needs backward computation.
I0628 11:35:07.774832 48903 net.cpp:226] roi_pool5 needs backward computation.
I0628 11:35:07.774835 48903 net.cpp:226] roi-data needs backward computation.
I0628 11:35:07.774839 48903 net.cpp:226] proposal needs backward computation.
I0628 11:35:07.774843 48903 net.cpp:226] rpn_cls_prob_reshape needs backward computation.
I0628 11:35:07.774847 48903 net.cpp:226] rpn_cls_prob needs backward computation.
I0628 11:35:07.774849 48903 net.cpp:226] rpn_loss_bbox needs backward computation.
I0628 11:35:07.774854 48903 net.cpp:226] rpn_loss_cls needs backward computation.
I0628 11:35:07.774858 48903 net.cpp:226] rpn-data needs backward computation.
I0628 11:35:07.774863 48903 net.cpp:226] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split needs backward computation.
I0628 11:35:07.774868 48903 net.cpp:226] rpn_cls_score_reshape needs backward computation.
I0628 11:35:07.774870 48903 net.cpp:226] rpn_bbox_pred_rpn_bbox_pred_0_split needs backward computation.
I0628 11:35:07.774873 48903 net.cpp:226] rpn_bbox_pred needs backward computation.
I0628 11:35:07.774878 48903 net.cpp:226] rpn_cls_score_rpn_cls_score_0_split needs backward computation.
I0628 11:35:07.774880 48903 net.cpp:226] rpn_cls_score needs backward computation.
I0628 11:35:07.774883 48903 net.cpp:226] rpn/output_rpn_relu/3x3_0_split needs backward computation.
I0628 11:35:07.774888 48903 net.cpp:226] rpn_relu/3x3 needs backward computation.
I0628 11:35:07.774890 48903 net.cpp:226] rpn_conv/3x3 needs backward computation.
I0628 11:35:07.774894 48903 net.cpp:226] newP2_newP2_0_split needs backward computation.
I0628 11:35:07.774897 48903 net.cpp:226] newP2 needs backward computation.
I0628 11:35:07.774900 48903 net.cpp:226] P2 needs backward computation.
I0628 11:35:07.774904 48903 net.cpp:226] upP3crop needs backward computation.
I0628 11:35:07.774929 48903 net.cpp:226] upP3 needs backward computation.
I0628 11:35:07.774947 48903 net.cpp:226] P3 needs backward computation.
I0628 11:35:07.774962 48903 net.cpp:226] upP4crop needs backward computation.
I0628 11:35:07.774976 48903 net.cpp:226] newC3_newC3_0_split needs backward computation.
I0628 11:35:07.774991 48903 net.cpp:226] newC3 needs backward computation.
I0628 11:35:07.775004 48903 net.cpp:226] upP4 needs backward computation.
I0628 11:35:07.775018 48903 net.cpp:226] P4 needs backward computation.
I0628 11:35:07.775033 48903 net.cpp:226] upP5crop needs backward computation.
I0628 11:35:07.775048 48903 net.cpp:226] newC4_newC4_0_split needs backward computation.
I0628 11:35:07.775070 48903 net.cpp:226] newC4 needs backward computation.
I0628 11:35:07.775084 48903 net.cpp:226] upP5 needs backward computation.
I0628 11:35:07.775099 48903 net.cpp:226] P5 needs backward computation.
I0628 11:35:07.775125 48903 net.cpp:226] pool5 needs backward computation.
I0628 11:35:07.775140 48903 net.cpp:226] conv5_3_relu5_3_0_split needs backward computation.
I0628 11:35:07.775164 48903 net.cpp:226] relu5_3 needs backward computation.
I0628 11:35:07.775179 48903 net.cpp:226] conv5_3 needs backward computation.
I0628 11:35:07.775203 48903 net.cpp:226] relu5_2 needs backward computation.
I0628 11:35:07.775218 48903 net.cpp:226] conv5_2 needs backward computation.
I0628 11:35:07.775233 48903 net.cpp:226] relu5_1 needs backward computation.
I0628 11:35:07.775249 48903 net.cpp:226] conv5_1 needs backward computation.
I0628 11:35:07.775269 48903 net.cpp:226] pool4 needs backward computation.
I0628 11:35:07.775283 48903 net.cpp:226] conv4_3_relu4_3_0_split needs backward computation.
I0628 11:35:07.775290 48903 net.cpp:226] relu4_3 needs backward computation.
I0628 11:35:07.775293 48903 net.cpp:226] conv4_3 needs backward computation.
I0628 11:35:07.775296 48903 net.cpp:226] relu4_2 needs backward computation.
I0628 11:35:07.775300 48903 net.cpp:226] conv4_2 needs backward computation.
I0628 11:35:07.775303 48903 net.cpp:226] relu4_1 needs backward computation.
I0628 11:35:07.775306 48903 net.cpp:226] conv4_1 needs backward computation.
I0628 11:35:07.775323 48903 net.cpp:226] pool3 needs backward computation.
I0628 11:35:07.775358 48903 net.cpp:226] conv3_3_relu3_3_0_split needs backward computation.
I0628 11:35:07.775370 48903 net.cpp:226] relu3_3 needs backward computation.
I0628 11:35:07.775373 48903 net.cpp:226] conv3_3 needs backward computation.
I0628 11:35:07.775377 48903 net.cpp:226] relu3_2 needs backward computation.
I0628 11:35:07.775380 48903 net.cpp:226] conv3_2 needs backward computation.
I0628 11:35:07.775383 48903 net.cpp:226] relu3_1 needs backward computation.
I0628 11:35:07.775387 48903 net.cpp:226] conv3_1 needs backward computation.
I0628 11:35:07.775430 48903 net.cpp:228] pool2 does not need backward computation.
I0628 11:35:07.775442 48903 net.cpp:228] relu2_2 does not need backward computation.
I0628 11:35:07.775446 48903 net.cpp:228] conv2_2 does not need backward computation.
I0628 11:35:07.775450 48903 net.cpp:228] relu2_1 does not need backward computation.
I0628 11:35:07.775472 48903 net.cpp:228] conv2_1 does not need backward computation.
I0628 11:35:07.775488 48903 net.cpp:228] pool1 does not need backward computation.
I0628 11:35:07.775504 48903 net.cpp:228] relu1_2 does not need backward computation.
I0628 11:35:07.775519 48903 net.cpp:228] conv1_2 does not need backward computation.
I0628 11:35:07.775534 48903 net.cpp:228] relu1_1 does not need backward computation.
I0628 11:35:07.775539 48903 net.cpp:228] conv1_1 does not need backward computation.
I0628 11:35:07.775544 48903 net.cpp:228] gt_boxes_input-data_2_split does not need backward computation.
I0628 11:35:07.775547 48903 net.cpp:228] im_info_input-data_1_split does not need backward computation.
I0628 11:35:07.775565 48903 net.cpp:228] data_input-data_0_split does not need backward computation.
I0628 11:35:07.775581 48903 net.cpp:228] input-data does not need backward computation.
I0628 11:35:07.775594 48903 net.cpp:270] This network produces output loss_bbox
I0628 11:35:07.775611 48903 net.cpp:270] This network produces output loss_cls
I0628 11:35:07.775625 48903 net.cpp:270] This network produces output rpn_cls_loss
I0628 11:35:07.775641 48903 net.cpp:270] This network produces output rpn_loss_bbox
I0628 11:35:07.775707 48903 net.cpp:283] Network initialization done.
I0628 11:35:07.775925 48903 solver.cpp:60] Solver scaffolding done.
Loading pretrained model weights from data/imagenet_models/VGG16.v2.caffemodel
[libprotobuf INFO google/protobuf/io/coded_stream.cc:610] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:81] The total number of bytes read was 553432430
I0628 11:35:11.486546 48903 net.cpp:816] Ignoring source layer fc6
I0628 11:35:11.500790 48903 net.cpp:816] Ignoring source layer fc8
I0628 11:35:11.500834 48903 net.cpp:816] Ignoring source layer prob
Solving...
9.64749e+08
3.21697e+09
2.69005e+09
3.77741e+09
2.30556e+09
2.74548e+09
3.55952e+09
1.28785e+09
9.84589e+08
7.94585e+08
8.36679e+07
4.37683e+07
3.09556e+07
512615
1.41213e+06
7.0625e+07
2.14834e+13
2.20239e+13
1.33958e+11
2.70233e+11
/home/ubuntu/Work/brbchen/unskychen/trying/p4/tools/../lib/fast_rcnn/bbox_transform.py:48: RuntimeWarning: overflow encountered in exp
  pred_w = np.exp(dw) * widths[:, np.newaxis]
/home/ubuntu/Work/brbchen/unskychen/trying/p4/tools/../lib/fast_rcnn/bbox_transform.py:48: RuntimeWarning: overflow encountered in multiply
  pred_w = np.exp(dw) * widths[:, np.newaxis]
/home/ubuntu/Work/brbchen/unskychen/trying/p4/tools/../lib/fast_rcnn/bbox_transform.py:49: RuntimeWarning: overflow encountered in exp
  pred_h = np.exp(dh) * heights[:, np.newaxis]
/home/ubuntu/Work/brbchen/unskychen/trying/p4/tools/../lib/fast_rcnn/bbox_transform.py:49: RuntimeWarning: overflow encountered in multiply
  pred_h = np.exp(dh) * heights[:, np.newaxis]
/home/ubuntu/Work/brbchen/unskychen/trying/p4/tools/../lib/rpn/proposal_target_layer.py:127: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future
  bbox_targets[ind, start:end] = bbox_target_data[ind, 1:]
/home/ubuntu/Work/brbchen/unskychen/trying/p4/tools/../lib/rpn/proposal_target_layer.py:128: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future
  bbox_inside_weights[ind, start:end] = cfg.TRAIN.BBOX_INSIDE_WEIGHTS
1.22353e+09
4.27647e+09
4.31651e+09
6.76394e+09
4.00318e+09
4.19178e+09
5.34557e+09
1.96869e+09
1.41934e+09
1.11105e+09
1.04229e+08
5.80754e+07
3.76682e+07
504501
1.38887e+06
8.72398e+07
2.61012e+13
2.67304e+13
1.60264e+11
3.34865e+11
I0628 11:35:12.579659 48903 solver.cpp:229] Iteration 0, loss = 476424
I0628 11:35:12.579722 48903 solver.cpp:245]     Train net output #0: loss_bbox = 13522.3 (* 1 = 13522.3 loss)
I0628 11:35:12.579733 48903 solver.cpp:245]     Train net output #1: loss_cls = 87.3365 (* 1 = 87.3365 loss)
I0628 11:35:12.579740 48903 solver.cpp:245]     Train net output #2: rpn_cls_loss = 17.3991 (* 1 = 17.3991 loss)
I0628 11:35:12.579744 48903 solver.cpp:245]     Train net output #3: rpn_loss_bbox = 409023 (* 1 = 409023 loss)
I0628 11:35:12.579754 48903 sgd_solver.cpp:106] Iteration 0, lr = 1e-05
1.38783e+09
4.53309e+09
3.97133e+09
4.99863e+09
1.72057e+11
8.15078e+12
4.73857e+14
1.24678e+16
9.58407e+17
8.15126e+19
1.85311e+21
1.57302e+23
1.14931e+25
7.24025e+25
6.32671e+24
3.02858e+19
2.60695e+37
inf
inf
inf
9.4687e+08
2.92463e+09
2.4194e+09
3.15387e+09
1.09436e+11
5.18483e+12
3.01637e+14
7.96813e+15
6.13709e+17
5.22821e+19
1.18983e+21
1.01285e+23
7.41817e+24
4.6497e+25
4.08334e+24
1.94254e+19
1.68539e+37
inf
inf
inf
1.39837e+09
4.71496e+09
4.37688e+09
5.58144e+09
inf
nan
nan
nan
nan
nan
inf
nan
nan
inf
nan
nan
nan
nan
nan
nan
/home/ubuntu/Work/brbchen/unskychen/trying/p4/tools/../lib/rpn/proposal_layer.py:175: RuntimeWarning: invalid value encountered in greater_equal
  keep = np.where((ws >= min_size) & (hs >= min_size))[0]
./experiments/scripts/FP_Net_end2end.sh: line 57: 48903 Floating point exception(core dumped) ./tools/train_net.py --gpu ${GPU_ID} --solver models/${PT_DIR}/${NET}/FP_Net_end2end/solver.prototxt --weights data/imagenet_models/${NET}.v2.caffemodel --imdb ${TRAIN_IMDB} --iters ${ITERS} --cfg experiments/cfgs/FP_Net_end2end.yml ${EXTRA_ARGS}

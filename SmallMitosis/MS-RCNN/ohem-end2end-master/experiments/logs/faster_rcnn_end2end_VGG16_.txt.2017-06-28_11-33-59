+ echo Logging output to experiments/logs/faster_rcnn_end2end_VGG16_.txt.2017-06-28_11-33-59
Logging output to experiments/logs/faster_rcnn_end2end_VGG16_.txt.2017-06-28_11-33-59
+ ./tools/train_net.py --gpu 0 --solver models/pascal_voc/VGG16/FP_Net_end2end/solver.prototxt --weights data/imagenet_models/VGG16.v2.caffemodel --imdb voc_2007_trainval --iters 70000 --cfg experiments/cfgs/FP_Net_end2end.yml
Called with args:
Namespace(cfg_file='experiments/cfgs/FP_Net_end2end.yml', gpu_id=0, imdb_name='voc_2007_trainval', max_iters=70000, pretrained_model='data/imagenet_models/VGG16.v2.caffemodel', randomize=False, set_cfgs=None, solver='models/pascal_voc/VGG16/FP_Net_end2end/solver.prototxt')
Using config:
{'DATA_DIR': '/home/ubuntu/Work/brbchen/unskychen/trying/p4/data',
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXP_DIR': 'FP_Net_end2end',
 'GPU_ID': 0,
 'MATLAB': 'matlab',
 'MODELS_DIR': '/home/ubuntu/Work/brbchen/unskychen/trying/p4/models/pascal_voc',
 'PIXEL_MEANS': array([[[ 102.9801,  115.9465,  122.7717]]]),
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Work/brbchen/unskychen/trying/p4',
 'TEST': {'BBOX_REG': True,
          'HAS_RPN': True,
          'MAX_SIZE': 1000,
          'NMS': 0.3,
          'PROPOSAL_METHOD': 'selective_search',
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.3,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALES': [600],
          'SVM': False},
 'TRAIN': {'ASPECT_GROUPING': True,
           'BATCH_SIZE': 256,
           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': True,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.3,
           'BG_THRESH_LO': 0.0,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.7,
           'HAS_RPN': True,
           'IMS_PER_BATCH': 1,
           'MAX_SIZE': 1000,
           'PROPOSAL_METHOD': 'gt',
           'RPN_BATCHSIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000,
           'SCALES': [600],
           'SNAPSHOT_INFIX': '',
           'SNAPSHOT_ITERS': 10000,
           'USE_FLIPPED': True,
           'USE_PREFETCH': False},
 'USE_GPU_NMS': True}
Loaded dataset `voc_2007_trainval` for training
Set proposal method: gt
Appending horizontally-flipped training examples...
voc_2007_trainval gt roidb loaded from /home/ubuntu/Work/brbchen/unskychen/trying/p4/data/cache/voc_2007_trainval_gt_roidb.pkl
done
Preparing training data...
done
33102 roidb entries
Output will be saved to `/home/ubuntu/Work/brbchen/unskychen/trying/p4/output/FP_Net_end2end/voc_2007_trainval`
Filtered 0 roidb entries: 33102 -> 33102
Computing bounding-box regression targets...
bbox target means:
[[ 0.  0.  0.  0.]
 [ 0.  0.  0.  0.]
 [ 0.  0.  0.  0.]
 [ 0.  0.  0.  0.]
 [ 0.  0.  0.  0.]
 [ 0.  0.  0.  0.]
 [ 0.  0.  0.  0.]
 [ 0.  0.  0.  0.]
 [ 0.  0.  0.  0.]
 [ 0.  0.  0.  0.]
 [ 0.  0.  0.  0.]
 [ 0.  0.  0.  0.]
 [ 0.  0.  0.  0.]
 [ 0.  0.  0.  0.]
 [ 0.  0.  0.  0.]
 [ 0.  0.  0.  0.]
 [ 0.  0.  0.  0.]
 [ 0.  0.  0.  0.]
 [ 0.  0.  0.  0.]
 [ 0.  0.  0.  0.]
 [ 0.  0.  0.  0.]]
[ 0.  0.  0.  0.]
bbox target stdevs:
[[ 0.1  0.1  0.2  0.2]
 [ 0.1  0.1  0.2  0.2]
 [ 0.1  0.1  0.2  0.2]
 [ 0.1  0.1  0.2  0.2]
 [ 0.1  0.1  0.2  0.2]
 [ 0.1  0.1  0.2  0.2]
 [ 0.1  0.1  0.2  0.2]
 [ 0.1  0.1  0.2  0.2]
 [ 0.1  0.1  0.2  0.2]
 [ 0.1  0.1  0.2  0.2]
 [ 0.1  0.1  0.2  0.2]
 [ 0.1  0.1  0.2  0.2]
 [ 0.1  0.1  0.2  0.2]
 [ 0.1  0.1  0.2  0.2]
 [ 0.1  0.1  0.2  0.2]
 [ 0.1  0.1  0.2  0.2]
 [ 0.1  0.1  0.2  0.2]
 [ 0.1  0.1  0.2  0.2]
 [ 0.1  0.1  0.2  0.2]
 [ 0.1  0.1  0.2  0.2]
 [ 0.1  0.1  0.2  0.2]]
[ 0.1  0.1  0.2  0.2]
Normalizing targets
done
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0628 11:34:17.489521 48693 solver.cpp:48] Initializing solver from parameters: 
train_net: "models/pascal_voc/VGG16/FP_Net_end2end/train.prototxt"
base_lr: 0.0001
display: 20
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 50000
snapshot: 0
snapshot_prefix: "fpn"
average_loss: 100
iter_size: 2
I0628 11:34:17.489574 48693 solver.cpp:81] Creating training net from train_net file: models/pascal_voc/VGG16/FP_Net_end2end/train.prototxt
I0628 11:34:17.491140 48693 net.cpp:49] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layers"
state {
  phase: TRAIN
}
layer {
  name: "input-data"
  type: "Python"
  top: "data"
  top: "im_info"
  top: "gt_boxes"
  python_param {
    module: "roi_data_layer.layer"
    layer: "RoIDataLayer"
    param_str: "\'num_classes\': 21"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "P5"
  type: "Convolution"
  bottom: "pool5"
  top: "P5"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "upP5"
  type: "Deconvolution"
  bottom: "P5"
  top: "upP5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 4
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "newC4"
  type: "Convolution"
  bottom: "conv5_3"
  top: "newC4"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "upP5crop"
  type: "Crop"
  bottom: "upP5"
  bottom: "newC4"
  top: "upP5crop"
  crop_param {
    axis: 2
    offset: 0
  }
}
layer {
  name: "P4"
  type: "Eltwise"
  bottom: "newC4"
  bottom: "upP5crop"
  top: "P4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "upP4"
  type: "Deconvolution"
  bottom: "P4"
  top: "upP4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 4
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "newC3"
  type: "Convolution"
  bottom: "conv4_3"
  top: "newC3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "upP4crop"
  type: "Crop"
  bottom: "upP4"
  bottom: "newC3"
  top: "upP4crop"
  crop_param {
    axis: 2
    offset: 0
  }
}
layer {
  name: "P3"
  type: "Eltwise"
  bottom: "newC3"
  bottom: "upP4crop"
  top: "P3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "upP3"
  type: "Deconvolution"
  bottom: "P3"
  top: "upP3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 4
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "upP3crop"
  type: "Crop"
  bottom: "upP3"
  bottom: "conv3_3"
  top: "upP3crop"
  crop_param {
    axis: 2
    offset: 0
  }
}
layer {
  name: "P2"
  type: "Eltwise"
  bottom: "conv3_3"
  bottom: "upP3crop"
  top: "P2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "newP2"
  type: "Convolution"
  bottom: "P2"
  top: "newP2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "rpn_conv/3x3"
  type: "Convolution"
  bottom: "newP2"
  top: "rpn/output"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_relu/3x3"
  type: "ReLU"
  bottom: "rpn/output"
  top: "rpn/output"
}
layer {
  name: "rpn_cls_score"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_cls_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 18
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_bbox_pred"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_bbox_pred"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 36
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_cls_score_reshape"
  type: "Reshape"
  bottom: "rpn_cls_score"
  top: "rpn_cls_score_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 2
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "rpn-data"
  type: "Python"
  bottom: "rpn_cls_score"
  bottom: "gt_boxes"
  bottom: "im_info"
  bottom: "data"
  top: "rpn_labels"
  top: "rpn_bbox_targets"
  top: "rpn_bbox_inside_weights"
  top: "rpn_bbox_outside_weights"
  python_param {
    module: "rpn.anchor_target_layer"
    layer: "AnchorTargetLayer"
    param_str: "\'feat_stride\': 4"
  }
}
layer {
  name: "rpn_loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "rpn_cls_score_reshape"
  bottom: "rpn_labels"
  top: "rpn_cls_loss"
  loss_weight: 1
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: -1
    normalize: true
  }
}
layer {
  name: "rpn_loss_bbox"
  type: "SmoothL1Loss"
  bottom: "rpn_bbox_pred"
  bottom: "rpn_bbox_targets"
  bottom: "rpn_bbox_inside_weights"
  bottom: "rpn_bbox_outside_weights"
  top: "rpn_loss_bbox"
  loss_weight: 1
  smooth_l1_loss_param {
    sigma: 3
  }
}
layer {
  name: "rpn_cls_prob"
  type: "Softmax"
  bottom: "rpn_cls_score_reshape"
  top: "rpn_cls_prob"
}
layer {
  name: "rpn_cls_prob_reshape"
  type: "Reshape"
  bottom: "rpn_cls_prob"
  top: "rpn_cls_prob_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 18
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "proposal"
  type: "Python"
  bottom: "rpn_cls_prob_reshape"
  bottom: "rpn_bbox_pred"
  bottom: "im_info"
  top: "rpn_rois"
  python_param {
    module: "rpn.proposal_layer"
    layer: "ProposalLayer"
    param_str: "\'feat_stride\': 4"
  }
}
layer {
  name: "roi-data"
  type: "Python"
  bottom: "rpn_rois"
  bottom: "gt_boxes"
  top: "rois"
  top: "labels"
  top: "bbox_targets"
  top: "bbox_inside_weights"
  top: "bbox_outside_weights"
  python_param {
    module: "rpn.proposal_target_layer"
    layer: "ProposalTargetLayer"
    param_str: "\'num_classes\': 21"
  }
}
layer {
  name: "roi_pool5"
  type: "ROIPooling"
  bottom: "newP2"
  bottom: "rois"
  top: "rcnn_pool5"
  roi_pooling_param {
    pooled_h: 7
    pooled_w: 7
    spatial_scale: 0.25
  }
}
layer {
  name: "rcnn_fc6"
  type: "InnerProduct"
  bottom: "rcnn_pool5"
  top: "rcnn_fc6"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "rcnn_fc6"
  top: "rcnn_fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "rcnn_fc6"
  top: "rcnn_fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "rcnn_fc6"
  top: "fc7"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "cls_score"
  type: "InnerProduct"
  bottom: "fc7"
  top: "cls_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 21
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bbox_pred"
  type: "InnerProduct"
  bottom: "fc7"
  top: "bbox_pred"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 84
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "cls_score"
  bottom: "labels"
  top: "loss_cls"
  loss_weight: 1
  propagate_down: true
  propagate_down: false
}
layer {
  name: "loss_bbox"
  type: "SmoothL1Loss"
  bottom: "bbox_pred"
  bottom: "bbox_targets"
  bottom: "bbox_inside_weights"
  bottom: "bbox_outside_weights"
  top: "loss_bbox"
  loss_weight: 1
}
I0628 11:34:17.491503 48693 layer_factory.hpp:77] Creating layer input-data
I0628 11:34:17.492538 48693 net.cpp:106] Creating Layer input-data
I0628 11:34:17.492563 48693 net.cpp:411] input-data -> data
I0628 11:34:17.492580 48693 net.cpp:411] input-data -> im_info
I0628 11:34:17.492614 48693 net.cpp:411] input-data -> gt_boxes
RoiDataLayer: name_to_top: {'gt_boxes': 2, 'data': 0, 'im_info': 1}
I0628 11:34:17.506455 48693 net.cpp:150] Setting up input-data
I0628 11:34:17.506522 48693 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0628 11:34:17.506541 48693 net.cpp:157] Top shape: 1 3 (3)
I0628 11:34:17.506556 48693 net.cpp:157] Top shape: 1 4 (4)
I0628 11:34:17.506568 48693 net.cpp:165] Memory required for data: 7200028
I0628 11:34:17.506583 48693 layer_factory.hpp:77] Creating layer data_input-data_0_split
I0628 11:34:17.506608 48693 net.cpp:106] Creating Layer data_input-data_0_split
I0628 11:34:17.506624 48693 net.cpp:454] data_input-data_0_split <- data
I0628 11:34:17.506644 48693 net.cpp:411] data_input-data_0_split -> data_input-data_0_split_0
I0628 11:34:17.506669 48693 net.cpp:411] data_input-data_0_split -> data_input-data_0_split_1
I0628 11:34:17.506721 48693 net.cpp:150] Setting up data_input-data_0_split
I0628 11:34:17.506736 48693 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0628 11:34:17.506742 48693 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0628 11:34:17.506745 48693 net.cpp:165] Memory required for data: 21600028
I0628 11:34:17.506749 48693 layer_factory.hpp:77] Creating layer im_info_input-data_1_split
I0628 11:34:17.506755 48693 net.cpp:106] Creating Layer im_info_input-data_1_split
I0628 11:34:17.506827 48693 net.cpp:454] im_info_input-data_1_split <- im_info
I0628 11:34:17.506851 48693 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_0
I0628 11:34:17.506884 48693 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_1
I0628 11:34:17.506935 48693 net.cpp:150] Setting up im_info_input-data_1_split
I0628 11:34:17.506948 48693 net.cpp:157] Top shape: 1 3 (3)
I0628 11:34:17.506953 48693 net.cpp:157] Top shape: 1 3 (3)
I0628 11:34:17.506956 48693 net.cpp:165] Memory required for data: 21600052
I0628 11:34:17.506959 48693 layer_factory.hpp:77] Creating layer gt_boxes_input-data_2_split
I0628 11:34:17.506981 48693 net.cpp:106] Creating Layer gt_boxes_input-data_2_split
I0628 11:34:17.507027 48693 net.cpp:454] gt_boxes_input-data_2_split <- gt_boxes
I0628 11:34:17.507043 48693 net.cpp:411] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_0
I0628 11:34:17.507050 48693 net.cpp:411] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_1
I0628 11:34:17.507086 48693 net.cpp:150] Setting up gt_boxes_input-data_2_split
I0628 11:34:17.507105 48693 net.cpp:157] Top shape: 1 4 (4)
I0628 11:34:17.507110 48693 net.cpp:157] Top shape: 1 4 (4)
I0628 11:34:17.507113 48693 net.cpp:165] Memory required for data: 21600084
I0628 11:34:17.507117 48693 layer_factory.hpp:77] Creating layer conv1_1
I0628 11:34:17.507148 48693 net.cpp:106] Creating Layer conv1_1
I0628 11:34:17.507171 48693 net.cpp:454] conv1_1 <- data_input-data_0_split_0
I0628 11:34:17.507199 48693 net.cpp:411] conv1_1 -> conv1_1
I0628 11:34:17.846088 48693 net.cpp:150] Setting up conv1_1
I0628 11:34:17.846135 48693 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0628 11:34:17.846140 48693 net.cpp:165] Memory required for data: 175200084
I0628 11:34:17.846159 48693 layer_factory.hpp:77] Creating layer relu1_1
I0628 11:34:17.846174 48693 net.cpp:106] Creating Layer relu1_1
I0628 11:34:17.846210 48693 net.cpp:454] relu1_1 <- conv1_1
I0628 11:34:17.846230 48693 net.cpp:397] relu1_1 -> conv1_1 (in-place)
I0628 11:34:17.846987 48693 net.cpp:150] Setting up relu1_1
I0628 11:34:17.847009 48693 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0628 11:34:17.847014 48693 net.cpp:165] Memory required for data: 328800084
I0628 11:34:17.847018 48693 layer_factory.hpp:77] Creating layer conv1_2
I0628 11:34:17.847030 48693 net.cpp:106] Creating Layer conv1_2
I0628 11:34:17.847055 48693 net.cpp:454] conv1_2 <- conv1_1
I0628 11:34:17.847074 48693 net.cpp:411] conv1_2 -> conv1_2
I0628 11:34:17.853171 48693 net.cpp:150] Setting up conv1_2
I0628 11:34:17.853195 48693 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0628 11:34:17.853200 48693 net.cpp:165] Memory required for data: 482400084
I0628 11:34:17.853210 48693 layer_factory.hpp:77] Creating layer relu1_2
I0628 11:34:17.853245 48693 net.cpp:106] Creating Layer relu1_2
I0628 11:34:17.853262 48693 net.cpp:454] relu1_2 <- conv1_2
I0628 11:34:17.853279 48693 net.cpp:397] relu1_2 -> conv1_2 (in-place)
I0628 11:34:17.853502 48693 net.cpp:150] Setting up relu1_2
I0628 11:34:17.853519 48693 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0628 11:34:17.853523 48693 net.cpp:165] Memory required for data: 636000084
I0628 11:34:17.853528 48693 layer_factory.hpp:77] Creating layer pool1
I0628 11:34:17.853543 48693 net.cpp:106] Creating Layer pool1
I0628 11:34:17.853564 48693 net.cpp:454] pool1 <- conv1_2
I0628 11:34:17.853588 48693 net.cpp:411] pool1 -> pool1
I0628 11:34:17.853673 48693 net.cpp:150] Setting up pool1
I0628 11:34:17.853688 48693 net.cpp:157] Top shape: 1 64 300 500 (9600000)
I0628 11:34:17.853690 48693 net.cpp:165] Memory required for data: 674400084
I0628 11:34:17.853694 48693 layer_factory.hpp:77] Creating layer conv2_1
I0628 11:34:17.853704 48693 net.cpp:106] Creating Layer conv2_1
I0628 11:34:17.853724 48693 net.cpp:454] conv2_1 <- pool1
I0628 11:34:17.853744 48693 net.cpp:411] conv2_1 -> conv2_1
I0628 11:34:17.857367 48693 net.cpp:150] Setting up conv2_1
I0628 11:34:17.857390 48693 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0628 11:34:17.857395 48693 net.cpp:165] Memory required for data: 751200084
I0628 11:34:17.857405 48693 layer_factory.hpp:77] Creating layer relu2_1
I0628 11:34:17.857439 48693 net.cpp:106] Creating Layer relu2_1
I0628 11:34:17.857458 48693 net.cpp:454] relu2_1 <- conv2_1
I0628 11:34:17.857482 48693 net.cpp:397] relu2_1 -> conv2_1 (in-place)
I0628 11:34:17.859073 48693 net.cpp:150] Setting up relu2_1
I0628 11:34:17.859092 48693 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0628 11:34:17.859097 48693 net.cpp:165] Memory required for data: 828000084
I0628 11:34:17.859100 48693 layer_factory.hpp:77] Creating layer conv2_2
I0628 11:34:17.859133 48693 net.cpp:106] Creating Layer conv2_2
I0628 11:34:17.859156 48693 net.cpp:454] conv2_2 <- conv2_1
I0628 11:34:17.859200 48693 net.cpp:411] conv2_2 -> conv2_2
I0628 11:34:17.862910 48693 net.cpp:150] Setting up conv2_2
I0628 11:34:17.862936 48693 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0628 11:34:17.862941 48693 net.cpp:165] Memory required for data: 904800084
I0628 11:34:17.862972 48693 layer_factory.hpp:77] Creating layer relu2_2
I0628 11:34:17.863008 48693 net.cpp:106] Creating Layer relu2_2
I0628 11:34:17.863031 48693 net.cpp:454] relu2_2 <- conv2_2
I0628 11:34:17.863054 48693 net.cpp:397] relu2_2 -> conv2_2 (in-place)
I0628 11:34:17.863818 48693 net.cpp:150] Setting up relu2_2
I0628 11:34:17.863839 48693 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0628 11:34:17.863844 48693 net.cpp:165] Memory required for data: 981600084
I0628 11:34:17.863848 48693 layer_factory.hpp:77] Creating layer pool2
I0628 11:34:17.863878 48693 net.cpp:106] Creating Layer pool2
I0628 11:34:17.863896 48693 net.cpp:454] pool2 <- conv2_2
I0628 11:34:17.863919 48693 net.cpp:411] pool2 -> pool2
I0628 11:34:17.863997 48693 net.cpp:150] Setting up pool2
I0628 11:34:17.864012 48693 net.cpp:157] Top shape: 1 128 150 250 (4800000)
I0628 11:34:17.864014 48693 net.cpp:165] Memory required for data: 1000800084
I0628 11:34:17.864018 48693 layer_factory.hpp:77] Creating layer conv3_1
I0628 11:34:17.864028 48693 net.cpp:106] Creating Layer conv3_1
I0628 11:34:17.864048 48693 net.cpp:454] conv3_1 <- pool2
I0628 11:34:17.864064 48693 net.cpp:411] conv3_1 -> conv3_1
I0628 11:34:17.867488 48693 net.cpp:150] Setting up conv3_1
I0628 11:34:17.867512 48693 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0628 11:34:17.867517 48693 net.cpp:165] Memory required for data: 1039200084
I0628 11:34:17.867527 48693 layer_factory.hpp:77] Creating layer relu3_1
I0628 11:34:17.867537 48693 net.cpp:106] Creating Layer relu3_1
I0628 11:34:17.867542 48693 net.cpp:454] relu3_1 <- conv3_1
I0628 11:34:17.867570 48693 net.cpp:397] relu3_1 -> conv3_1 (in-place)
I0628 11:34:17.868124 48693 net.cpp:150] Setting up relu3_1
I0628 11:34:17.868145 48693 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0628 11:34:17.868149 48693 net.cpp:165] Memory required for data: 1077600084
I0628 11:34:17.868154 48693 layer_factory.hpp:77] Creating layer conv3_2
I0628 11:34:17.868183 48693 net.cpp:106] Creating Layer conv3_2
I0628 11:34:17.868211 48693 net.cpp:454] conv3_2 <- conv3_1
I0628 11:34:17.868229 48693 net.cpp:411] conv3_2 -> conv3_2
I0628 11:34:17.873353 48693 net.cpp:150] Setting up conv3_2
I0628 11:34:17.873378 48693 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0628 11:34:17.873383 48693 net.cpp:165] Memory required for data: 1116000084
I0628 11:34:17.873389 48693 layer_factory.hpp:77] Creating layer relu3_2
I0628 11:34:17.873420 48693 net.cpp:106] Creating Layer relu3_2
I0628 11:34:17.873450 48693 net.cpp:454] relu3_2 <- conv3_2
I0628 11:34:17.873471 48693 net.cpp:397] relu3_2 -> conv3_2 (in-place)
I0628 11:34:17.873877 48693 net.cpp:150] Setting up relu3_2
I0628 11:34:17.873894 48693 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0628 11:34:17.873898 48693 net.cpp:165] Memory required for data: 1154400084
I0628 11:34:17.873901 48693 layer_factory.hpp:77] Creating layer conv3_3
I0628 11:34:17.873931 48693 net.cpp:106] Creating Layer conv3_3
I0628 11:34:17.873950 48693 net.cpp:454] conv3_3 <- conv3_2
I0628 11:34:17.873975 48693 net.cpp:411] conv3_3 -> conv3_3
I0628 11:34:17.878744 48693 net.cpp:150] Setting up conv3_3
I0628 11:34:17.878788 48693 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0628 11:34:17.878794 48693 net.cpp:165] Memory required for data: 1192800084
I0628 11:34:17.878801 48693 layer_factory.hpp:77] Creating layer relu3_3
I0628 11:34:17.878832 48693 net.cpp:106] Creating Layer relu3_3
I0628 11:34:17.878852 48693 net.cpp:454] relu3_3 <- conv3_3
I0628 11:34:17.878876 48693 net.cpp:397] relu3_3 -> conv3_3 (in-place)
I0628 11:34:17.880358 48693 net.cpp:150] Setting up relu3_3
I0628 11:34:17.880379 48693 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0628 11:34:17.880384 48693 net.cpp:165] Memory required for data: 1231200084
I0628 11:34:17.880388 48693 layer_factory.hpp:77] Creating layer conv3_3_relu3_3_0_split
I0628 11:34:17.880398 48693 net.cpp:106] Creating Layer conv3_3_relu3_3_0_split
I0628 11:34:17.880401 48693 net.cpp:454] conv3_3_relu3_3_0_split <- conv3_3
I0628 11:34:17.880406 48693 net.cpp:411] conv3_3_relu3_3_0_split -> conv3_3_relu3_3_0_split_0
I0628 11:34:17.880414 48693 net.cpp:411] conv3_3_relu3_3_0_split -> conv3_3_relu3_3_0_split_1
I0628 11:34:17.880444 48693 net.cpp:411] conv3_3_relu3_3_0_split -> conv3_3_relu3_3_0_split_2
I0628 11:34:17.880520 48693 net.cpp:150] Setting up conv3_3_relu3_3_0_split
I0628 11:34:17.880534 48693 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0628 11:34:17.880539 48693 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0628 11:34:17.880542 48693 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0628 11:34:17.880545 48693 net.cpp:165] Memory required for data: 1346400084
I0628 11:34:17.880565 48693 layer_factory.hpp:77] Creating layer pool3
I0628 11:34:17.880583 48693 net.cpp:106] Creating Layer pool3
I0628 11:34:17.880596 48693 net.cpp:454] pool3 <- conv3_3_relu3_3_0_split_0
I0628 11:34:17.880627 48693 net.cpp:411] pool3 -> pool3
I0628 11:34:17.880687 48693 net.cpp:150] Setting up pool3
I0628 11:34:17.880700 48693 net.cpp:157] Top shape: 1 256 75 125 (2400000)
I0628 11:34:17.880703 48693 net.cpp:165] Memory required for data: 1356000084
I0628 11:34:17.880707 48693 layer_factory.hpp:77] Creating layer conv4_1
I0628 11:34:17.880717 48693 net.cpp:106] Creating Layer conv4_1
I0628 11:34:17.880736 48693 net.cpp:454] conv4_1 <- pool3
I0628 11:34:17.880753 48693 net.cpp:411] conv4_1 -> conv4_1
I0628 11:34:17.886926 48693 net.cpp:150] Setting up conv4_1
I0628 11:34:17.886951 48693 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0628 11:34:17.886955 48693 net.cpp:165] Memory required for data: 1375200084
I0628 11:34:17.886962 48693 layer_factory.hpp:77] Creating layer relu4_1
I0628 11:34:17.886996 48693 net.cpp:106] Creating Layer relu4_1
I0628 11:34:17.887018 48693 net.cpp:454] relu4_1 <- conv4_1
I0628 11:34:17.887042 48693 net.cpp:397] relu4_1 -> conv4_1 (in-place)
I0628 11:34:17.887840 48693 net.cpp:150] Setting up relu4_1
I0628 11:34:17.887861 48693 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0628 11:34:17.887866 48693 net.cpp:165] Memory required for data: 1394400084
I0628 11:34:17.887871 48693 layer_factory.hpp:77] Creating layer conv4_2
I0628 11:34:17.887902 48693 net.cpp:106] Creating Layer conv4_2
I0628 11:34:17.887919 48693 net.cpp:454] conv4_2 <- conv4_1
I0628 11:34:17.887946 48693 net.cpp:411] conv4_2 -> conv4_2
I0628 11:34:17.896008 48693 net.cpp:150] Setting up conv4_2
I0628 11:34:17.896035 48693 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0628 11:34:17.896064 48693 net.cpp:165] Memory required for data: 1413600084
I0628 11:34:17.896088 48693 layer_factory.hpp:77] Creating layer relu4_2
I0628 11:34:17.896111 48693 net.cpp:106] Creating Layer relu4_2
I0628 11:34:17.896124 48693 net.cpp:454] relu4_2 <- conv4_2
I0628 11:34:17.896144 48693 net.cpp:397] relu4_2 -> conv4_2 (in-place)
I0628 11:34:17.896359 48693 net.cpp:150] Setting up relu4_2
I0628 11:34:17.896378 48693 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0628 11:34:17.896381 48693 net.cpp:165] Memory required for data: 1432800084
I0628 11:34:17.896386 48693 layer_factory.hpp:77] Creating layer conv4_3
I0628 11:34:17.896416 48693 net.cpp:106] Creating Layer conv4_3
I0628 11:34:17.896432 48693 net.cpp:454] conv4_3 <- conv4_2
I0628 11:34:17.896451 48693 net.cpp:411] conv4_3 -> conv4_3
I0628 11:34:17.904760 48693 net.cpp:150] Setting up conv4_3
I0628 11:34:17.904788 48693 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0628 11:34:17.904793 48693 net.cpp:165] Memory required for data: 1452000084
I0628 11:34:17.904799 48693 layer_factory.hpp:77] Creating layer relu4_3
I0628 11:34:17.904829 48693 net.cpp:106] Creating Layer relu4_3
I0628 11:34:17.904850 48693 net.cpp:454] relu4_3 <- conv4_3
I0628 11:34:17.904873 48693 net.cpp:397] relu4_3 -> conv4_3 (in-place)
I0628 11:34:17.905632 48693 net.cpp:150] Setting up relu4_3
I0628 11:34:17.905654 48693 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0628 11:34:17.905658 48693 net.cpp:165] Memory required for data: 1471200084
I0628 11:34:17.905663 48693 layer_factory.hpp:77] Creating layer conv4_3_relu4_3_0_split
I0628 11:34:17.905673 48693 net.cpp:106] Creating Layer conv4_3_relu4_3_0_split
I0628 11:34:17.905676 48693 net.cpp:454] conv4_3_relu4_3_0_split <- conv4_3
I0628 11:34:17.905683 48693 net.cpp:411] conv4_3_relu4_3_0_split -> conv4_3_relu4_3_0_split_0
I0628 11:34:17.905711 48693 net.cpp:411] conv4_3_relu4_3_0_split -> conv4_3_relu4_3_0_split_1
I0628 11:34:17.905781 48693 net.cpp:150] Setting up conv4_3_relu4_3_0_split
I0628 11:34:17.905796 48693 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0628 11:34:17.905800 48693 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0628 11:34:17.905803 48693 net.cpp:165] Memory required for data: 1509600084
I0628 11:34:17.905807 48693 layer_factory.hpp:77] Creating layer pool4
I0628 11:34:17.905833 48693 net.cpp:106] Creating Layer pool4
I0628 11:34:17.905848 48693 net.cpp:454] pool4 <- conv4_3_relu4_3_0_split_0
I0628 11:34:17.905870 48693 net.cpp:411] pool4 -> pool4
I0628 11:34:17.905951 48693 net.cpp:150] Setting up pool4
I0628 11:34:17.905964 48693 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0628 11:34:17.905968 48693 net.cpp:165] Memory required for data: 1514502996
I0628 11:34:17.905972 48693 layer_factory.hpp:77] Creating layer conv5_1
I0628 11:34:17.905982 48693 net.cpp:106] Creating Layer conv5_1
I0628 11:34:17.906002 48693 net.cpp:454] conv5_1 <- pool4
I0628 11:34:17.906018 48693 net.cpp:411] conv5_1 -> conv5_1
I0628 11:34:17.914132 48693 net.cpp:150] Setting up conv5_1
I0628 11:34:17.914157 48693 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0628 11:34:17.914161 48693 net.cpp:165] Memory required for data: 1519405908
I0628 11:34:17.914170 48693 layer_factory.hpp:77] Creating layer relu5_1
I0628 11:34:17.914199 48693 net.cpp:106] Creating Layer relu5_1
I0628 11:34:17.914224 48693 net.cpp:454] relu5_1 <- conv5_1
I0628 11:34:17.914244 48693 net.cpp:397] relu5_1 -> conv5_1 (in-place)
I0628 11:34:17.915241 48693 net.cpp:150] Setting up relu5_1
I0628 11:34:17.915261 48693 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0628 11:34:17.915264 48693 net.cpp:165] Memory required for data: 1524308820
I0628 11:34:17.915268 48693 layer_factory.hpp:77] Creating layer conv5_2
I0628 11:34:17.915304 48693 net.cpp:106] Creating Layer conv5_2
I0628 11:34:17.915333 48693 net.cpp:454] conv5_2 <- conv5_1
I0628 11:34:17.915351 48693 net.cpp:411] conv5_2 -> conv5_2
I0628 11:34:17.923877 48693 net.cpp:150] Setting up conv5_2
I0628 11:34:17.923903 48693 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0628 11:34:17.923908 48693 net.cpp:165] Memory required for data: 1529211732
I0628 11:34:17.923915 48693 layer_factory.hpp:77] Creating layer relu5_2
I0628 11:34:17.923949 48693 net.cpp:106] Creating Layer relu5_2
I0628 11:34:17.923969 48693 net.cpp:454] relu5_2 <- conv5_2
I0628 11:34:17.923996 48693 net.cpp:397] relu5_2 -> conv5_2 (in-place)
I0628 11:34:17.925025 48693 net.cpp:150] Setting up relu5_2
I0628 11:34:17.925042 48693 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0628 11:34:17.925046 48693 net.cpp:165] Memory required for data: 1534114644
I0628 11:34:17.925050 48693 layer_factory.hpp:77] Creating layer conv5_3
I0628 11:34:17.925081 48693 net.cpp:106] Creating Layer conv5_3
I0628 11:34:17.925104 48693 net.cpp:454] conv5_3 <- conv5_2
I0628 11:34:17.925127 48693 net.cpp:411] conv5_3 -> conv5_3
I0628 11:34:17.932755 48693 net.cpp:150] Setting up conv5_3
I0628 11:34:17.932780 48693 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0628 11:34:17.932785 48693 net.cpp:165] Memory required for data: 1539017556
I0628 11:34:17.932791 48693 layer_factory.hpp:77] Creating layer relu5_3
I0628 11:34:17.932826 48693 net.cpp:106] Creating Layer relu5_3
I0628 11:34:17.932843 48693 net.cpp:454] relu5_3 <- conv5_3
I0628 11:34:17.932860 48693 net.cpp:397] relu5_3 -> conv5_3 (in-place)
I0628 11:34:17.933790 48693 net.cpp:150] Setting up relu5_3
I0628 11:34:17.933815 48693 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0628 11:34:17.933818 48693 net.cpp:165] Memory required for data: 1543920468
I0628 11:34:17.933822 48693 layer_factory.hpp:77] Creating layer conv5_3_relu5_3_0_split
I0628 11:34:17.933830 48693 net.cpp:106] Creating Layer conv5_3_relu5_3_0_split
I0628 11:34:17.933833 48693 net.cpp:454] conv5_3_relu5_3_0_split <- conv5_3
I0628 11:34:17.933840 48693 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_0
I0628 11:34:17.933845 48693 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_1
I0628 11:34:17.933928 48693 net.cpp:150] Setting up conv5_3_relu5_3_0_split
I0628 11:34:17.933943 48693 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0628 11:34:17.933948 48693 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0628 11:34:17.933950 48693 net.cpp:165] Memory required for data: 1553726292
I0628 11:34:17.933954 48693 layer_factory.hpp:77] Creating layer pool5
I0628 11:34:17.933980 48693 net.cpp:106] Creating Layer pool5
I0628 11:34:17.933996 48693 net.cpp:454] pool5 <- conv5_3_relu5_3_0_split_0
I0628 11:34:17.934018 48693 net.cpp:411] pool5 -> pool5
I0628 11:34:17.934087 48693 net.cpp:150] Setting up pool5
I0628 11:34:17.934100 48693 net.cpp:157] Top shape: 1 512 19 32 (311296)
I0628 11:34:17.934104 48693 net.cpp:165] Memory required for data: 1554971476
I0628 11:34:17.934108 48693 layer_factory.hpp:77] Creating layer P5
I0628 11:34:17.934120 48693 net.cpp:106] Creating Layer P5
I0628 11:34:17.934139 48693 net.cpp:454] P5 <- pool5
I0628 11:34:17.934159 48693 net.cpp:411] P5 -> P5
I0628 11:34:17.938899 48693 net.cpp:150] Setting up P5
I0628 11:34:17.938922 48693 net.cpp:157] Top shape: 1 256 19 32 (155648)
I0628 11:34:17.938926 48693 net.cpp:165] Memory required for data: 1555594068
I0628 11:34:17.938933 48693 layer_factory.hpp:77] Creating layer upP5
I0628 11:34:17.938972 48693 net.cpp:106] Creating Layer upP5
I0628 11:34:17.938989 48693 net.cpp:454] upP5 <- P5
I0628 11:34:17.939008 48693 net.cpp:411] upP5 -> upP5
I0628 11:34:17.965303 48693 net.cpp:150] Setting up upP5
I0628 11:34:17.965353 48693 net.cpp:157] Top shape: 1 256 38 64 (622592)
I0628 11:34:17.965356 48693 net.cpp:165] Memory required for data: 1558084436
I0628 11:34:17.965366 48693 layer_factory.hpp:77] Creating layer newC4
I0628 11:34:17.965384 48693 net.cpp:106] Creating Layer newC4
I0628 11:34:17.965425 48693 net.cpp:454] newC4 <- conv5_3_relu5_3_0_split_1
I0628 11:34:17.965442 48693 net.cpp:411] newC4 -> newC4
I0628 11:34:17.968546 48693 net.cpp:150] Setting up newC4
I0628 11:34:17.968570 48693 net.cpp:157] Top shape: 1 256 38 63 (612864)
I0628 11:34:17.968598 48693 net.cpp:165] Memory required for data: 1560535892
I0628 11:34:17.968613 48693 layer_factory.hpp:77] Creating layer newC4_newC4_0_split
I0628 11:34:17.968631 48693 net.cpp:106] Creating Layer newC4_newC4_0_split
I0628 11:34:17.968641 48693 net.cpp:454] newC4_newC4_0_split <- newC4
I0628 11:34:17.968648 48693 net.cpp:411] newC4_newC4_0_split -> newC4_newC4_0_split_0
I0628 11:34:17.968675 48693 net.cpp:411] newC4_newC4_0_split -> newC4_newC4_0_split_1
I0628 11:34:17.968736 48693 net.cpp:150] Setting up newC4_newC4_0_split
I0628 11:34:17.968749 48693 net.cpp:157] Top shape: 1 256 38 63 (612864)
I0628 11:34:17.968752 48693 net.cpp:157] Top shape: 1 256 38 63 (612864)
I0628 11:34:17.968755 48693 net.cpp:165] Memory required for data: 1565438804
I0628 11:34:17.968775 48693 layer_factory.hpp:77] Creating layer upP5crop
I0628 11:34:17.968796 48693 net.cpp:106] Creating Layer upP5crop
I0628 11:34:17.968814 48693 net.cpp:454] upP5crop <- upP5
I0628 11:34:17.968824 48693 net.cpp:454] upP5crop <- newC4_newC4_0_split_0
I0628 11:34:17.968830 48693 net.cpp:411] upP5crop -> upP5crop
I0628 11:34:17.968947 48693 net.cpp:150] Setting up upP5crop
I0628 11:34:17.968961 48693 net.cpp:157] Top shape: 1 256 38 63 (612864)
I0628 11:34:17.968963 48693 net.cpp:165] Memory required for data: 1567890260
I0628 11:34:17.968967 48693 layer_factory.hpp:77] Creating layer P4
I0628 11:34:17.968992 48693 net.cpp:106] Creating Layer P4
I0628 11:34:17.969002 48693 net.cpp:454] P4 <- newC4_newC4_0_split_1
I0628 11:34:17.969007 48693 net.cpp:454] P4 <- upP5crop
I0628 11:34:17.969015 48693 net.cpp:411] P4 -> P4
I0628 11:34:17.969056 48693 net.cpp:150] Setting up P4
I0628 11:34:17.969069 48693 net.cpp:157] Top shape: 1 256 38 63 (612864)
I0628 11:34:17.969071 48693 net.cpp:165] Memory required for data: 1570341716
I0628 11:34:17.969075 48693 layer_factory.hpp:77] Creating layer upP4
I0628 11:34:17.969084 48693 net.cpp:106] Creating Layer upP4
I0628 11:34:17.969086 48693 net.cpp:454] upP4 <- P4
I0628 11:34:17.969094 48693 net.cpp:411] upP4 -> upP4
I0628 11:34:17.995035 48693 net.cpp:150] Setting up upP4
I0628 11:34:17.995057 48693 net.cpp:157] Top shape: 1 256 76 126 (2451456)
I0628 11:34:17.995061 48693 net.cpp:165] Memory required for data: 1580147540
I0628 11:34:17.995066 48693 layer_factory.hpp:77] Creating layer newC3
I0628 11:34:17.995076 48693 net.cpp:106] Creating Layer newC3
I0628 11:34:17.995080 48693 net.cpp:454] newC3 <- conv4_3_relu4_3_0_split_1
I0628 11:34:17.995088 48693 net.cpp:411] newC3 -> newC3
I0628 11:34:18.000159 48693 net.cpp:150] Setting up newC3
I0628 11:34:18.000181 48693 net.cpp:157] Top shape: 1 256 75 125 (2400000)
I0628 11:34:18.000186 48693 net.cpp:165] Memory required for data: 1589747540
I0628 11:34:18.000202 48693 layer_factory.hpp:77] Creating layer newC3_newC3_0_split
I0628 11:34:18.000211 48693 net.cpp:106] Creating Layer newC3_newC3_0_split
I0628 11:34:18.000216 48693 net.cpp:454] newC3_newC3_0_split <- newC3
I0628 11:34:18.000222 48693 net.cpp:411] newC3_newC3_0_split -> newC3_newC3_0_split_0
I0628 11:34:18.000244 48693 net.cpp:411] newC3_newC3_0_split -> newC3_newC3_0_split_1
I0628 11:34:18.000293 48693 net.cpp:150] Setting up newC3_newC3_0_split
I0628 11:34:18.000304 48693 net.cpp:157] Top shape: 1 256 75 125 (2400000)
I0628 11:34:18.000309 48693 net.cpp:157] Top shape: 1 256 75 125 (2400000)
I0628 11:34:18.000313 48693 net.cpp:165] Memory required for data: 1608947540
I0628 11:34:18.000315 48693 layer_factory.hpp:77] Creating layer upP4crop
I0628 11:34:18.000324 48693 net.cpp:106] Creating Layer upP4crop
I0628 11:34:18.000329 48693 net.cpp:454] upP4crop <- upP4
I0628 11:34:18.000332 48693 net.cpp:454] upP4crop <- newC3_newC3_0_split_0
I0628 11:34:18.000339 48693 net.cpp:411] upP4crop -> upP4crop
I0628 11:34:18.000442 48693 net.cpp:150] Setting up upP4crop
I0628 11:34:18.000455 48693 net.cpp:157] Top shape: 1 256 75 125 (2400000)
I0628 11:34:18.000458 48693 net.cpp:165] Memory required for data: 1618547540
I0628 11:34:18.000463 48693 layer_factory.hpp:77] Creating layer P3
I0628 11:34:18.000468 48693 net.cpp:106] Creating Layer P3
I0628 11:34:18.000471 48693 net.cpp:454] P3 <- newC3_newC3_0_split_1
I0628 11:34:18.000475 48693 net.cpp:454] P3 <- upP4crop
I0628 11:34:18.000479 48693 net.cpp:411] P3 -> P3
I0628 11:34:18.000510 48693 net.cpp:150] Setting up P3
I0628 11:34:18.000521 48693 net.cpp:157] Top shape: 1 256 75 125 (2400000)
I0628 11:34:18.000524 48693 net.cpp:165] Memory required for data: 1628147540
I0628 11:34:18.000529 48693 layer_factory.hpp:77] Creating layer upP3
I0628 11:34:18.000538 48693 net.cpp:106] Creating Layer upP3
I0628 11:34:18.000541 48693 net.cpp:454] upP3 <- P3
I0628 11:34:18.000550 48693 net.cpp:411] upP3 -> upP3
I0628 11:34:18.026412 48693 net.cpp:150] Setting up upP3
I0628 11:34:18.026435 48693 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0628 11:34:18.026439 48693 net.cpp:165] Memory required for data: 1666547540
I0628 11:34:18.026445 48693 layer_factory.hpp:77] Creating layer upP3crop
I0628 11:34:18.026451 48693 net.cpp:106] Creating Layer upP3crop
I0628 11:34:18.026455 48693 net.cpp:454] upP3crop <- upP3
I0628 11:34:18.026460 48693 net.cpp:454] upP3crop <- conv3_3_relu3_3_0_split_1
I0628 11:34:18.026465 48693 net.cpp:411] upP3crop -> upP3crop
I0628 11:34:18.026574 48693 net.cpp:150] Setting up upP3crop
I0628 11:34:18.026587 48693 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0628 11:34:18.026590 48693 net.cpp:165] Memory required for data: 1704947540
I0628 11:34:18.026594 48693 layer_factory.hpp:77] Creating layer P2
I0628 11:34:18.026599 48693 net.cpp:106] Creating Layer P2
I0628 11:34:18.026603 48693 net.cpp:454] P2 <- conv3_3_relu3_3_0_split_2
I0628 11:34:18.026607 48693 net.cpp:454] P2 <- upP3crop
I0628 11:34:18.026614 48693 net.cpp:411] P2 -> P2
I0628 11:34:18.026640 48693 net.cpp:150] Setting up P2
I0628 11:34:18.026654 48693 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0628 11:34:18.026657 48693 net.cpp:165] Memory required for data: 1743347540
I0628 11:34:18.026661 48693 layer_factory.hpp:77] Creating layer newP2
I0628 11:34:18.026671 48693 net.cpp:106] Creating Layer newP2
I0628 11:34:18.026690 48693 net.cpp:454] newP2 <- P2
I0628 11:34:18.026695 48693 net.cpp:411] newP2 -> newP2
I0628 11:34:18.035012 48693 net.cpp:150] Setting up newP2
I0628 11:34:18.035037 48693 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0628 11:34:18.035043 48693 net.cpp:165] Memory required for data: 1781747540
I0628 11:34:18.035051 48693 layer_factory.hpp:77] Creating layer newP2_newP2_0_split
I0628 11:34:18.035058 48693 net.cpp:106] Creating Layer newP2_newP2_0_split
I0628 11:34:18.035078 48693 net.cpp:454] newP2_newP2_0_split <- newP2
I0628 11:34:18.035084 48693 net.cpp:411] newP2_newP2_0_split -> newP2_newP2_0_split_0
I0628 11:34:18.035091 48693 net.cpp:411] newP2_newP2_0_split -> newP2_newP2_0_split_1
I0628 11:34:18.035145 48693 net.cpp:150] Setting up newP2_newP2_0_split
I0628 11:34:18.035156 48693 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0628 11:34:18.035161 48693 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0628 11:34:18.035164 48693 net.cpp:165] Memory required for data: 1858547540
I0628 11:34:18.035167 48693 layer_factory.hpp:77] Creating layer rpn_conv/3x3
I0628 11:34:18.035178 48693 net.cpp:106] Creating Layer rpn_conv/3x3
I0628 11:34:18.035182 48693 net.cpp:454] rpn_conv/3x3 <- newP2_newP2_0_split_0
I0628 11:34:18.035194 48693 net.cpp:411] rpn_conv/3x3 -> rpn/output
I0628 11:34:18.069245 48693 net.cpp:150] Setting up rpn_conv/3x3
I0628 11:34:18.069270 48693 net.cpp:157] Top shape: 1 512 150 250 (19200000)
I0628 11:34:18.069274 48693 net.cpp:165] Memory required for data: 1935347540
I0628 11:34:18.069283 48693 layer_factory.hpp:77] Creating layer rpn_relu/3x3
I0628 11:34:18.069293 48693 net.cpp:106] Creating Layer rpn_relu/3x3
I0628 11:34:18.069311 48693 net.cpp:454] rpn_relu/3x3 <- rpn/output
I0628 11:34:18.069317 48693 net.cpp:397] rpn_relu/3x3 -> rpn/output (in-place)
I0628 11:34:18.069850 48693 net.cpp:150] Setting up rpn_relu/3x3
I0628 11:34:18.069866 48693 net.cpp:157] Top shape: 1 512 150 250 (19200000)
I0628 11:34:18.069870 48693 net.cpp:165] Memory required for data: 2012147540
I0628 11:34:18.069875 48693 layer_factory.hpp:77] Creating layer rpn/output_rpn_relu/3x3_0_split
I0628 11:34:18.069885 48693 net.cpp:106] Creating Layer rpn/output_rpn_relu/3x3_0_split
I0628 11:34:18.069890 48693 net.cpp:454] rpn/output_rpn_relu/3x3_0_split <- rpn/output
I0628 11:34:18.069895 48693 net.cpp:411] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_0
I0628 11:34:18.069910 48693 net.cpp:411] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_1
I0628 11:34:18.069960 48693 net.cpp:150] Setting up rpn/output_rpn_relu/3x3_0_split
I0628 11:34:18.069972 48693 net.cpp:157] Top shape: 1 512 150 250 (19200000)
I0628 11:34:18.069977 48693 net.cpp:157] Top shape: 1 512 150 250 (19200000)
I0628 11:34:18.069979 48693 net.cpp:165] Memory required for data: 2165747540
I0628 11:34:18.069983 48693 layer_factory.hpp:77] Creating layer rpn_cls_score
I0628 11:34:18.069998 48693 net.cpp:106] Creating Layer rpn_cls_score
I0628 11:34:18.070005 48693 net.cpp:454] rpn_cls_score <- rpn/output_rpn_relu/3x3_0_split_0
I0628 11:34:18.070013 48693 net.cpp:411] rpn_cls_score -> rpn_cls_score
I0628 11:34:18.075364 48693 net.cpp:150] Setting up rpn_cls_score
I0628 11:34:18.075387 48693 net.cpp:157] Top shape: 1 18 150 250 (675000)
I0628 11:34:18.075392 48693 net.cpp:165] Memory required for data: 2168447540
I0628 11:34:18.075402 48693 layer_factory.hpp:77] Creating layer rpn_cls_score_rpn_cls_score_0_split
I0628 11:34:18.075424 48693 net.cpp:106] Creating Layer rpn_cls_score_rpn_cls_score_0_split
I0628 11:34:18.075429 48693 net.cpp:454] rpn_cls_score_rpn_cls_score_0_split <- rpn_cls_score
I0628 11:34:18.075435 48693 net.cpp:411] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_0
I0628 11:34:18.075441 48693 net.cpp:411] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_1
I0628 11:34:18.075495 48693 net.cpp:150] Setting up rpn_cls_score_rpn_cls_score_0_split
I0628 11:34:18.075507 48693 net.cpp:157] Top shape: 1 18 150 250 (675000)
I0628 11:34:18.075512 48693 net.cpp:157] Top shape: 1 18 150 250 (675000)
I0628 11:34:18.075515 48693 net.cpp:165] Memory required for data: 2173847540
I0628 11:34:18.075518 48693 layer_factory.hpp:77] Creating layer rpn_bbox_pred
I0628 11:34:18.075529 48693 net.cpp:106] Creating Layer rpn_bbox_pred
I0628 11:34:18.075533 48693 net.cpp:454] rpn_bbox_pred <- rpn/output_rpn_relu/3x3_0_split_1
I0628 11:34:18.075541 48693 net.cpp:411] rpn_bbox_pred -> rpn_bbox_pred
I0628 11:34:18.088533 48693 net.cpp:150] Setting up rpn_bbox_pred
I0628 11:34:18.088557 48693 net.cpp:157] Top shape: 1 36 150 250 (1350000)
I0628 11:34:18.088562 48693 net.cpp:165] Memory required for data: 2179247540
I0628 11:34:18.088568 48693 layer_factory.hpp:77] Creating layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0628 11:34:18.088575 48693 net.cpp:106] Creating Layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0628 11:34:18.088579 48693 net.cpp:454] rpn_bbox_pred_rpn_bbox_pred_0_split <- rpn_bbox_pred
I0628 11:34:18.088587 48693 net.cpp:411] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0628 11:34:18.088601 48693 net.cpp:411] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0628 11:34:18.088661 48693 net.cpp:150] Setting up rpn_bbox_pred_rpn_bbox_pred_0_split
I0628 11:34:18.088675 48693 net.cpp:157] Top shape: 1 36 150 250 (1350000)
I0628 11:34:18.088678 48693 net.cpp:157] Top shape: 1 36 150 250 (1350000)
I0628 11:34:18.088681 48693 net.cpp:165] Memory required for data: 2190047540
I0628 11:34:18.088685 48693 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape
I0628 11:34:18.088697 48693 net.cpp:106] Creating Layer rpn_cls_score_reshape
I0628 11:34:18.088701 48693 net.cpp:454] rpn_cls_score_reshape <- rpn_cls_score_rpn_cls_score_0_split_0
I0628 11:34:18.088708 48693 net.cpp:411] rpn_cls_score_reshape -> rpn_cls_score_reshape
I0628 11:34:18.088748 48693 net.cpp:150] Setting up rpn_cls_score_reshape
I0628 11:34:18.088760 48693 net.cpp:157] Top shape: 1 2 1350 250 (675000)
I0628 11:34:18.088764 48693 net.cpp:165] Memory required for data: 2192747540
I0628 11:34:18.088768 48693 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0628 11:34:18.088773 48693 net.cpp:106] Creating Layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0628 11:34:18.088776 48693 net.cpp:454] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split <- rpn_cls_score_reshape
I0628 11:34:18.088783 48693 net.cpp:411] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0628 11:34:18.088789 48693 net.cpp:411] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0628 11:34:18.088840 48693 net.cpp:150] Setting up rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0628 11:34:18.088850 48693 net.cpp:157] Top shape: 1 2 1350 250 (675000)
I0628 11:34:18.088856 48693 net.cpp:157] Top shape: 1 2 1350 250 (675000)
I0628 11:34:18.088860 48693 net.cpp:165] Memory required for data: 2198147540
I0628 11:34:18.088862 48693 layer_factory.hpp:77] Creating layer rpn-data
I0628 11:34:18.089561 48693 net.cpp:106] Creating Layer rpn-data
I0628 11:34:18.089582 48693 net.cpp:454] rpn-data <- rpn_cls_score_rpn_cls_score_0_split_1
I0628 11:34:18.089589 48693 net.cpp:454] rpn-data <- gt_boxes_input-data_2_split_0
I0628 11:34:18.089594 48693 net.cpp:454] rpn-data <- im_info_input-data_1_split_0
I0628 11:34:18.089599 48693 net.cpp:454] rpn-data <- data_input-data_0_split_1
I0628 11:34:18.089604 48693 net.cpp:411] rpn-data -> rpn_labels
I0628 11:34:18.089612 48693 net.cpp:411] rpn-data -> rpn_bbox_targets
I0628 11:34:18.089618 48693 net.cpp:411] rpn-data -> rpn_bbox_inside_weights
I0628 11:34:18.089624 48693 net.cpp:411] rpn-data -> rpn_bbox_outside_weights
I0628 11:34:18.091917 48693 net.cpp:150] Setting up rpn-data
I0628 11:34:18.091941 48693 net.cpp:157] Top shape: 1 1 1350 250 (337500)
I0628 11:34:18.091948 48693 net.cpp:157] Top shape: 1 36 150 250 (1350000)
I0628 11:34:18.091951 48693 net.cpp:157] Top shape: 1 36 150 250 (1350000)
I0628 11:34:18.091955 48693 net.cpp:157] Top shape: 1 36 150 250 (1350000)
I0628 11:34:18.091958 48693 net.cpp:165] Memory required for data: 2215697540
I0628 11:34:18.091962 48693 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0628 11:34:18.091981 48693 net.cpp:106] Creating Layer rpn_loss_cls
I0628 11:34:18.091992 48693 net.cpp:454] rpn_loss_cls <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0628 11:34:18.091998 48693 net.cpp:454] rpn_loss_cls <- rpn_labels
I0628 11:34:18.092005 48693 net.cpp:411] rpn_loss_cls -> rpn_cls_loss
I0628 11:34:18.092018 48693 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0628 11:34:18.093940 48693 net.cpp:150] Setting up rpn_loss_cls
I0628 11:34:18.093962 48693 net.cpp:157] Top shape: (1)
I0628 11:34:18.093966 48693 net.cpp:160]     with loss weight 1
I0628 11:34:18.093991 48693 net.cpp:165] Memory required for data: 2215697544
I0628 11:34:18.093997 48693 layer_factory.hpp:77] Creating layer rpn_loss_bbox
I0628 11:34:18.094008 48693 net.cpp:106] Creating Layer rpn_loss_bbox
I0628 11:34:18.094017 48693 net.cpp:454] rpn_loss_bbox <- rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0628 11:34:18.094023 48693 net.cpp:454] rpn_loss_bbox <- rpn_bbox_targets
I0628 11:34:18.094027 48693 net.cpp:454] rpn_loss_bbox <- rpn_bbox_inside_weights
I0628 11:34:18.094032 48693 net.cpp:454] rpn_loss_bbox <- rpn_bbox_outside_weights
I0628 11:34:18.094036 48693 net.cpp:411] rpn_loss_bbox -> rpn_loss_bbox
I0628 11:34:18.103675 48693 net.cpp:150] Setting up rpn_loss_bbox
I0628 11:34:18.103695 48693 net.cpp:157] Top shape: (1)
I0628 11:34:18.103699 48693 net.cpp:160]     with loss weight 1
I0628 11:34:18.103708 48693 net.cpp:165] Memory required for data: 2215697548
I0628 11:34:18.103713 48693 layer_factory.hpp:77] Creating layer rpn_cls_prob
I0628 11:34:18.103721 48693 net.cpp:106] Creating Layer rpn_cls_prob
I0628 11:34:18.103725 48693 net.cpp:454] rpn_cls_prob <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0628 11:34:18.103731 48693 net.cpp:411] rpn_cls_prob -> rpn_cls_prob
I0628 11:34:18.104584 48693 net.cpp:150] Setting up rpn_cls_prob
I0628 11:34:18.104604 48693 net.cpp:157] Top shape: 1 2 1350 250 (675000)
I0628 11:34:18.104609 48693 net.cpp:165] Memory required for data: 2218397548
I0628 11:34:18.104614 48693 layer_factory.hpp:77] Creating layer rpn_cls_prob_reshape
I0628 11:34:18.104626 48693 net.cpp:106] Creating Layer rpn_cls_prob_reshape
I0628 11:34:18.104645 48693 net.cpp:454] rpn_cls_prob_reshape <- rpn_cls_prob
I0628 11:34:18.104653 48693 net.cpp:411] rpn_cls_prob_reshape -> rpn_cls_prob_reshape
I0628 11:34:18.104687 48693 net.cpp:150] Setting up rpn_cls_prob_reshape
I0628 11:34:18.104702 48693 net.cpp:157] Top shape: 1 18 150 250 (675000)
I0628 11:34:18.104706 48693 net.cpp:165] Memory required for data: 2221097548
I0628 11:34:18.104709 48693 layer_factory.hpp:77] Creating layer proposal
I0628 11:34:18.105623 48693 net.cpp:106] Creating Layer proposal
I0628 11:34:18.105649 48693 net.cpp:454] proposal <- rpn_cls_prob_reshape
I0628 11:34:18.105656 48693 net.cpp:454] proposal <- rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0628 11:34:18.105660 48693 net.cpp:454] proposal <- im_info_input-data_1_split_1
I0628 11:34:18.105666 48693 net.cpp:411] proposal -> rpn_rois
I0628 11:34:18.106508 48693 net.cpp:150] Setting up proposal
I0628 11:34:18.106534 48693 net.cpp:157] Top shape: 1 5 (5)
I0628 11:34:18.106537 48693 net.cpp:165] Memory required for data: 2221097568
I0628 11:34:18.106542 48693 layer_factory.hpp:77] Creating layer roi-data
I0628 11:34:18.106739 48693 net.cpp:106] Creating Layer roi-data
I0628 11:34:18.106758 48693 net.cpp:454] roi-data <- rpn_rois
I0628 11:34:18.106765 48693 net.cpp:454] roi-data <- gt_boxes_input-data_2_split_1
I0628 11:34:18.106802 48693 net.cpp:411] roi-data -> rois
I0628 11:34:18.106812 48693 net.cpp:411] roi-data -> labels
I0628 11:34:18.106818 48693 net.cpp:411] roi-data -> bbox_targets
I0628 11:34:18.106824 48693 net.cpp:411] roi-data -> bbox_inside_weights
I0628 11:34:18.106835 48693 net.cpp:411] roi-data -> bbox_outside_weights
I0628 11:34:18.107235 48693 net.cpp:150] Setting up roi-data
I0628 11:34:18.107257 48693 net.cpp:157] Top shape: 1 5 (5)
I0628 11:34:18.107262 48693 net.cpp:157] Top shape: 1 1 (1)
I0628 11:34:18.107265 48693 net.cpp:157] Top shape: 1 84 (84)
I0628 11:34:18.107270 48693 net.cpp:157] Top shape: 1 84 (84)
I0628 11:34:18.107272 48693 net.cpp:157] Top shape: 1 84 (84)
I0628 11:34:18.107275 48693 net.cpp:165] Memory required for data: 2221098600
I0628 11:34:18.107280 48693 layer_factory.hpp:77] Creating layer roi_pool5
I0628 11:34:18.107290 48693 net.cpp:106] Creating Layer roi_pool5
I0628 11:34:18.107301 48693 net.cpp:454] roi_pool5 <- newP2_newP2_0_split_1
I0628 11:34:18.107306 48693 net.cpp:454] roi_pool5 <- rois
I0628 11:34:18.107313 48693 net.cpp:411] roi_pool5 -> rcnn_pool5
I0628 11:34:18.107323 48693 roi_pooling_layer.cpp:30] Spatial scale: 0.25
I0628 11:34:18.107381 48693 net.cpp:150] Setting up roi_pool5
I0628 11:34:18.107393 48693 net.cpp:157] Top shape: 1 256 7 7 (12544)
I0628 11:34:18.107398 48693 net.cpp:165] Memory required for data: 2221148776
I0628 11:34:18.107401 48693 layer_factory.hpp:77] Creating layer rcnn_fc6
I0628 11:34:18.107414 48693 net.cpp:106] Creating Layer rcnn_fc6
I0628 11:34:18.107419 48693 net.cpp:454] rcnn_fc6 <- rcnn_pool5
I0628 11:34:18.107424 48693 net.cpp:411] rcnn_fc6 -> rcnn_fc6
I0628 11:34:18.444423 48693 net.cpp:150] Setting up rcnn_fc6
I0628 11:34:18.444476 48693 net.cpp:157] Top shape: 1 4096 (4096)
I0628 11:34:18.444481 48693 net.cpp:165] Memory required for data: 2221165160
I0628 11:34:18.444494 48693 layer_factory.hpp:77] Creating layer relu6
I0628 11:34:18.444504 48693 net.cpp:106] Creating Layer relu6
I0628 11:34:18.444511 48693 net.cpp:454] relu6 <- rcnn_fc6
I0628 11:34:18.444519 48693 net.cpp:397] relu6 -> rcnn_fc6 (in-place)
I0628 11:34:18.445540 48693 net.cpp:150] Setting up relu6
I0628 11:34:18.445562 48693 net.cpp:157] Top shape: 1 4096 (4096)
I0628 11:34:18.445566 48693 net.cpp:165] Memory required for data: 2221181544
I0628 11:34:18.445571 48693 layer_factory.hpp:77] Creating layer drop6
I0628 11:34:18.445585 48693 net.cpp:106] Creating Layer drop6
I0628 11:34:18.445590 48693 net.cpp:454] drop6 <- rcnn_fc6
I0628 11:34:18.445595 48693 net.cpp:397] drop6 -> rcnn_fc6 (in-place)
I0628 11:34:18.445639 48693 net.cpp:150] Setting up drop6
I0628 11:34:18.445652 48693 net.cpp:157] Top shape: 1 4096 (4096)
I0628 11:34:18.445655 48693 net.cpp:165] Memory required for data: 2221197928
I0628 11:34:18.445658 48693 layer_factory.hpp:77] Creating layer fc7
I0628 11:34:18.445669 48693 net.cpp:106] Creating Layer fc7
I0628 11:34:18.445673 48693 net.cpp:454] fc7 <- rcnn_fc6
I0628 11:34:18.445679 48693 net.cpp:411] fc7 -> fc7
I0628 11:34:18.558315 48693 net.cpp:150] Setting up fc7
I0628 11:34:18.558367 48693 net.cpp:157] Top shape: 1 4096 (4096)
I0628 11:34:18.558372 48693 net.cpp:165] Memory required for data: 2221214312
I0628 11:34:18.558383 48693 layer_factory.hpp:77] Creating layer relu7
I0628 11:34:18.558398 48693 net.cpp:106] Creating Layer relu7
I0628 11:34:18.558404 48693 net.cpp:454] relu7 <- fc7
I0628 11:34:18.558411 48693 net.cpp:397] relu7 -> fc7 (in-place)
I0628 11:34:18.558677 48693 net.cpp:150] Setting up relu7
I0628 11:34:18.558692 48693 net.cpp:157] Top shape: 1 4096 (4096)
I0628 11:34:18.558696 48693 net.cpp:165] Memory required for data: 2221230696
I0628 11:34:18.558701 48693 layer_factory.hpp:77] Creating layer drop7
I0628 11:34:18.558713 48693 net.cpp:106] Creating Layer drop7
I0628 11:34:18.558717 48693 net.cpp:454] drop7 <- fc7
I0628 11:34:18.558722 48693 net.cpp:397] drop7 -> fc7 (in-place)
I0628 11:34:18.558768 48693 net.cpp:150] Setting up drop7
I0628 11:34:18.558799 48693 net.cpp:157] Top shape: 1 4096 (4096)
I0628 11:34:18.558802 48693 net.cpp:165] Memory required for data: 2221247080
I0628 11:34:18.558805 48693 layer_factory.hpp:77] Creating layer fc7_drop7_0_split
I0628 11:34:18.558812 48693 net.cpp:106] Creating Layer fc7_drop7_0_split
I0628 11:34:18.558815 48693 net.cpp:454] fc7_drop7_0_split <- fc7
I0628 11:34:18.558822 48693 net.cpp:411] fc7_drop7_0_split -> fc7_drop7_0_split_0
I0628 11:34:18.558830 48693 net.cpp:411] fc7_drop7_0_split -> fc7_drop7_0_split_1
I0628 11:34:18.558881 48693 net.cpp:150] Setting up fc7_drop7_0_split
I0628 11:34:18.558894 48693 net.cpp:157] Top shape: 1 4096 (4096)
I0628 11:34:18.558898 48693 net.cpp:157] Top shape: 1 4096 (4096)
I0628 11:34:18.558902 48693 net.cpp:165] Memory required for data: 2221279848
I0628 11:34:18.558904 48693 layer_factory.hpp:77] Creating layer cls_score
I0628 11:34:18.558915 48693 net.cpp:106] Creating Layer cls_score
I0628 11:34:18.558919 48693 net.cpp:454] cls_score <- fc7_drop7_0_split_0
I0628 11:34:18.558928 48693 net.cpp:411] cls_score -> cls_score
I0628 11:34:18.561101 48693 net.cpp:150] Setting up cls_score
I0628 11:34:18.561115 48693 net.cpp:157] Top shape: 1 21 (21)
I0628 11:34:18.561120 48693 net.cpp:165] Memory required for data: 2221279932
I0628 11:34:18.561125 48693 layer_factory.hpp:77] Creating layer bbox_pred
I0628 11:34:18.561132 48693 net.cpp:106] Creating Layer bbox_pred
I0628 11:34:18.561136 48693 net.cpp:454] bbox_pred <- fc7_drop7_0_split_1
I0628 11:34:18.561144 48693 net.cpp:411] bbox_pred -> bbox_pred
I0628 11:34:18.570307 48693 net.cpp:150] Setting up bbox_pred
I0628 11:34:18.570328 48693 net.cpp:157] Top shape: 1 84 (84)
I0628 11:34:18.570333 48693 net.cpp:165] Memory required for data: 2221280268
I0628 11:34:18.570339 48693 layer_factory.hpp:77] Creating layer loss_cls
I0628 11:34:18.570346 48693 net.cpp:106] Creating Layer loss_cls
I0628 11:34:18.570351 48693 net.cpp:454] loss_cls <- cls_score
I0628 11:34:18.570356 48693 net.cpp:454] loss_cls <- labels
I0628 11:34:18.570361 48693 net.cpp:411] loss_cls -> loss_cls
I0628 11:34:18.570369 48693 layer_factory.hpp:77] Creating layer loss_cls
I0628 11:34:18.571310 48693 net.cpp:150] Setting up loss_cls
I0628 11:34:18.571331 48693 net.cpp:157] Top shape: (1)
I0628 11:34:18.571336 48693 net.cpp:160]     with loss weight 1
I0628 11:34:18.571349 48693 net.cpp:165] Memory required for data: 2221280272
I0628 11:34:18.571353 48693 layer_factory.hpp:77] Creating layer loss_bbox
I0628 11:34:18.571360 48693 net.cpp:106] Creating Layer loss_bbox
I0628 11:34:18.571364 48693 net.cpp:454] loss_bbox <- bbox_pred
I0628 11:34:18.571372 48693 net.cpp:454] loss_bbox <- bbox_targets
I0628 11:34:18.571377 48693 net.cpp:454] loss_bbox <- bbox_inside_weights
I0628 11:34:18.571380 48693 net.cpp:454] loss_bbox <- bbox_outside_weights
I0628 11:34:18.571384 48693 net.cpp:411] loss_bbox -> loss_bbox
I0628 11:34:18.571480 48693 net.cpp:150] Setting up loss_bbox
I0628 11:34:18.571493 48693 net.cpp:157] Top shape: (1)
I0628 11:34:18.571497 48693 net.cpp:160]     with loss weight 1
I0628 11:34:18.571501 48693 net.cpp:165] Memory required for data: 2221280276
I0628 11:34:18.571506 48693 net.cpp:226] loss_bbox needs backward computation.
I0628 11:34:18.571509 48693 net.cpp:226] loss_cls needs backward computation.
I0628 11:34:18.571512 48693 net.cpp:226] bbox_pred needs backward computation.
I0628 11:34:18.571516 48693 net.cpp:226] cls_score needs backward computation.
I0628 11:34:18.571519 48693 net.cpp:226] fc7_drop7_0_split needs backward computation.
I0628 11:34:18.571522 48693 net.cpp:226] drop7 needs backward computation.
I0628 11:34:18.571526 48693 net.cpp:226] relu7 needs backward computation.
I0628 11:34:18.571528 48693 net.cpp:226] fc7 needs backward computation.
I0628 11:34:18.571532 48693 net.cpp:226] drop6 needs backward computation.
I0628 11:34:18.571534 48693 net.cpp:226] relu6 needs backward computation.
I0628 11:34:18.571538 48693 net.cpp:226] rcnn_fc6 needs backward computation.
I0628 11:34:18.571542 48693 net.cpp:226] roi_pool5 needs backward computation.
I0628 11:34:18.571545 48693 net.cpp:226] roi-data needs backward computation.
I0628 11:34:18.571552 48693 net.cpp:226] proposal needs backward computation.
I0628 11:34:18.571557 48693 net.cpp:226] rpn_cls_prob_reshape needs backward computation.
I0628 11:34:18.571560 48693 net.cpp:226] rpn_cls_prob needs backward computation.
I0628 11:34:18.571564 48693 net.cpp:226] rpn_loss_bbox needs backward computation.
I0628 11:34:18.571568 48693 net.cpp:226] rpn_loss_cls needs backward computation.
I0628 11:34:18.571573 48693 net.cpp:226] rpn-data needs backward computation.
I0628 11:34:18.571578 48693 net.cpp:226] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split needs backward computation.
I0628 11:34:18.571583 48693 net.cpp:226] rpn_cls_score_reshape needs backward computation.
I0628 11:34:18.571586 48693 net.cpp:226] rpn_bbox_pred_rpn_bbox_pred_0_split needs backward computation.
I0628 11:34:18.571590 48693 net.cpp:226] rpn_bbox_pred needs backward computation.
I0628 11:34:18.571594 48693 net.cpp:226] rpn_cls_score_rpn_cls_score_0_split needs backward computation.
I0628 11:34:18.571597 48693 net.cpp:226] rpn_cls_score needs backward computation.
I0628 11:34:18.571601 48693 net.cpp:226] rpn/output_rpn_relu/3x3_0_split needs backward computation.
I0628 11:34:18.571605 48693 net.cpp:226] rpn_relu/3x3 needs backward computation.
I0628 11:34:18.571609 48693 net.cpp:226] rpn_conv/3x3 needs backward computation.
I0628 11:34:18.571612 48693 net.cpp:226] newP2_newP2_0_split needs backward computation.
I0628 11:34:18.571615 48693 net.cpp:226] newP2 needs backward computation.
I0628 11:34:18.571619 48693 net.cpp:226] P2 needs backward computation.
I0628 11:34:18.571624 48693 net.cpp:226] upP3crop needs backward computation.
I0628 11:34:18.571627 48693 net.cpp:226] upP3 needs backward computation.
I0628 11:34:18.571630 48693 net.cpp:226] P3 needs backward computation.
I0628 11:34:18.571635 48693 net.cpp:226] upP4crop needs backward computation.
I0628 11:34:18.571638 48693 net.cpp:226] newC3_newC3_0_split needs backward computation.
I0628 11:34:18.571641 48693 net.cpp:226] newC3 needs backward computation.
I0628 11:34:18.571645 48693 net.cpp:226] upP4 needs backward computation.
I0628 11:34:18.571650 48693 net.cpp:226] P4 needs backward computation.
I0628 11:34:18.571652 48693 net.cpp:226] upP5crop needs backward computation.
I0628 11:34:18.571656 48693 net.cpp:226] newC4_newC4_0_split needs backward computation.
I0628 11:34:18.571660 48693 net.cpp:226] newC4 needs backward computation.
I0628 11:34:18.571666 48693 net.cpp:226] upP5 needs backward computation.
I0628 11:34:18.571671 48693 net.cpp:226] P5 needs backward computation.
I0628 11:34:18.571673 48693 net.cpp:226] pool5 needs backward computation.
I0628 11:34:18.571677 48693 net.cpp:226] conv5_3_relu5_3_0_split needs backward computation.
I0628 11:34:18.571681 48693 net.cpp:226] relu5_3 needs backward computation.
I0628 11:34:18.571684 48693 net.cpp:226] conv5_3 needs backward computation.
I0628 11:34:18.571687 48693 net.cpp:226] relu5_2 needs backward computation.
I0628 11:34:18.571691 48693 net.cpp:226] conv5_2 needs backward computation.
I0628 11:34:18.571694 48693 net.cpp:226] relu5_1 needs backward computation.
I0628 11:34:18.571697 48693 net.cpp:226] conv5_1 needs backward computation.
I0628 11:34:18.571701 48693 net.cpp:226] pool4 needs backward computation.
I0628 11:34:18.571704 48693 net.cpp:226] conv4_3_relu4_3_0_split needs backward computation.
I0628 11:34:18.571708 48693 net.cpp:226] relu4_3 needs backward computation.
I0628 11:34:18.571712 48693 net.cpp:226] conv4_3 needs backward computation.
I0628 11:34:18.571715 48693 net.cpp:226] relu4_2 needs backward computation.
I0628 11:34:18.571718 48693 net.cpp:226] conv4_2 needs backward computation.
I0628 11:34:18.571722 48693 net.cpp:226] relu4_1 needs backward computation.
I0628 11:34:18.571725 48693 net.cpp:226] conv4_1 needs backward computation.
I0628 11:34:18.571728 48693 net.cpp:226] pool3 needs backward computation.
I0628 11:34:18.571732 48693 net.cpp:226] conv3_3_relu3_3_0_split needs backward computation.
I0628 11:34:18.571735 48693 net.cpp:226] relu3_3 needs backward computation.
I0628 11:34:18.571738 48693 net.cpp:226] conv3_3 needs backward computation.
I0628 11:34:18.571741 48693 net.cpp:226] relu3_2 needs backward computation.
I0628 11:34:18.571745 48693 net.cpp:226] conv3_2 needs backward computation.
I0628 11:34:18.571748 48693 net.cpp:226] relu3_1 needs backward computation.
I0628 11:34:18.571751 48693 net.cpp:226] conv3_1 needs backward computation.
I0628 11:34:18.571755 48693 net.cpp:228] pool2 does not need backward computation.
I0628 11:34:18.571758 48693 net.cpp:228] relu2_2 does not need backward computation.
I0628 11:34:18.571761 48693 net.cpp:228] conv2_2 does not need backward computation.
I0628 11:34:18.571765 48693 net.cpp:228] relu2_1 does not need backward computation.
I0628 11:34:18.571768 48693 net.cpp:228] conv2_1 does not need backward computation.
I0628 11:34:18.571772 48693 net.cpp:228] pool1 does not need backward computation.
I0628 11:34:18.571775 48693 net.cpp:228] relu1_2 does not need backward computation.
I0628 11:34:18.571779 48693 net.cpp:228] conv1_2 does not need backward computation.
I0628 11:34:18.571782 48693 net.cpp:228] relu1_1 does not need backward computation.
I0628 11:34:18.571786 48693 net.cpp:228] conv1_1 does not need backward computation.
I0628 11:34:18.571790 48693 net.cpp:228] gt_boxes_input-data_2_split does not need backward computation.
I0628 11:34:18.571794 48693 net.cpp:228] im_info_input-data_1_split does not need backward computation.
I0628 11:34:18.571799 48693 net.cpp:228] data_input-data_0_split does not need backward computation.
I0628 11:34:18.571805 48693 net.cpp:228] input-data does not need backward computation.
I0628 11:34:18.571808 48693 net.cpp:270] This network produces output loss_bbox
I0628 11:34:18.571811 48693 net.cpp:270] This network produces output loss_cls
I0628 11:34:18.571815 48693 net.cpp:270] This network produces output rpn_cls_loss
I0628 11:34:18.571818 48693 net.cpp:270] This network produces output rpn_loss_bbox
I0628 11:34:18.571872 48693 net.cpp:283] Network initialization done.
I0628 11:34:18.572069 48693 solver.cpp:60] Solver scaffolding done.
Loading pretrained model weights from data/imagenet_models/VGG16.v2.caffemodel
[libprotobuf INFO google/protobuf/io/coded_stream.cc:610] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:81] The total number of bytes read was 553432430
I0628 11:34:19.642891 48693 net.cpp:816] Ignoring source layer fc6
I0628 11:34:19.657280 48693 net.cpp:816] Ignoring source layer fc8
I0628 11:34:19.657316 48693 net.cpp:816] Ignoring source layer prob
Solving...
9.64749e+08
3.21697e+09
2.69005e+09
3.77741e+09
2.30556e+09
2.74548e+09
3.55952e+09
1.28785e+09
9.84589e+08
7.94585e+08
8.36679e+07
4.37683e+07
3.09556e+07
512615
1.41213e+06
7.0625e+07
2.14834e+13
2.20239e+13
1.33958e+11
2.70233e+11
/home/ubuntu/Work/brbchen/unskychen/trying/p4/tools/../lib/fast_rcnn/bbox_transform.py:48: RuntimeWarning: overflow encountered in exp
  pred_w = np.exp(dw) * widths[:, np.newaxis]
/home/ubuntu/Work/brbchen/unskychen/trying/p4/tools/../lib/fast_rcnn/bbox_transform.py:48: RuntimeWarning: overflow encountered in multiply
  pred_w = np.exp(dw) * widths[:, np.newaxis]
/home/ubuntu/Work/brbchen/unskychen/trying/p4/tools/../lib/fast_rcnn/bbox_transform.py:49: RuntimeWarning: overflow encountered in exp
  pred_h = np.exp(dh) * heights[:, np.newaxis]
/home/ubuntu/Work/brbchen/unskychen/trying/p4/tools/../lib/fast_rcnn/bbox_transform.py:49: RuntimeWarning: overflow encountered in multiply
  pred_h = np.exp(dh) * heights[:, np.newaxis]
/home/ubuntu/Work/brbchen/unskychen/trying/p4/tools/../lib/rpn/proposal_target_layer.py:127: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future
  bbox_targets[ind, start:end] = bbox_target_data[ind, 1:]
/home/ubuntu/Work/brbchen/unskychen/trying/p4/tools/../lib/rpn/proposal_target_layer.py:128: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future
  bbox_inside_weights[ind, start:end] = cfg.TRAIN.BBOX_INSIDE_WEIGHTS
1.22353e+09
4.27647e+09
4.31651e+09
6.76394e+09
4.00318e+09
4.19178e+09
5.34557e+09
1.96869e+09
1.41934e+09
1.11105e+09
1.04229e+08
5.80754e+07
3.76682e+07
504501
1.38887e+06
8.72398e+07
2.61012e+13
2.67304e+13
1.60264e+11
3.34865e+11
I0628 11:34:20.442960 48693 solver.cpp:229] Iteration 0, loss = 476424
I0628 11:34:20.443023 48693 solver.cpp:245]     Train net output #0: loss_bbox = 13522.3 (* 1 = 13522.3 loss)
I0628 11:34:20.443032 48693 solver.cpp:245]     Train net output #1: loss_cls = 87.3365 (* 1 = 87.3365 loss)
I0628 11:34:20.443039 48693 solver.cpp:245]     Train net output #2: rpn_cls_loss = 17.3991 (* 1 = 17.3991 loss)
I0628 11:34:20.443045 48693 solver.cpp:245]     Train net output #3: rpn_loss_bbox = 409023 (* 1 = 409023 loss)
I0628 11:34:20.443055 48693 sgd_solver.cpp:106] Iteration 0, lr = 0.0001
1.38783e+09
4.53309e+09
3.97133e+09
4.99863e+09
1.71767e+12
8.03218e+14
4.65328e+17
1.2318e+20
9.49737e+22
8.11067e+25
1.86891e+28
1.59226e+31
1.17047e+34
7.35073e+35
7.53395e+33
3.05074e+25
nan
nan
nan
nan
/home/ubuntu/Work/brbchen/unskychen/trying/p4/tools/../lib/rpn/proposal_layer.py:175: RuntimeWarning: invalid value encountered in greater_equal
  keep = np.where((ws >= min_size) & (hs >= min_size))[0]
./experiments/scripts/FP_Net_end2end.sh: line 57: 48693 Floating point exception(core dumped) ./tools/train_net.py --gpu ${GPU_ID} --solver models/${PT_DIR}/${NET}/FP_Net_end2end/solver.prototxt --weights data/imagenet_models/${NET}.v2.caffemodel --imdb ${TRAIN_IMDB} --iters ${ITERS} --cfg experiments/cfgs/FP_Net_end2end.yml ${EXTRA_ARGS}
